{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awjans/CopilotForPRsAdoption/blob/main/scripts/HumanDev.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection/Cleaning Overview\n",
        "1. **PR identification**\n",
        "   * Queried GitHub via GraphQL for PRs whose description contained the phrase **“Generated by Copilot”** or any of the marker tags:\n",
        "\n",
        "     * `copilot:summary`\n",
        "     * `copilot:walkthrough`\n",
        "     * `copilot:poem`\n",
        "     * `copilot:all`\n",
        "\n",
        "2. **Scope**\n",
        "   * Collected **18,256 PRs** from **146 early-adopter repositories** during **March 2023 – August 2023**.\n",
        "\n",
        "3. **Control set**\n",
        "   * For the same repositories, gathered **54,188 PRs** that did **not** contain any Copilot marker.\n",
        "   * These served as the **untreated (control) group** for the **RQ2 comparison**.\n",
        "\n",
        "4. **Bot filtering**\n",
        "   * Removed PRs and comments authored by bots using the **high-precision method** of **Golzadeh et al. (2022)**, which included:\n",
        "     * (i) Usernames ending with “bot”\n",
        "     * (ii) A curated list of **527 known bot accounts**\n",
        "\n",
        "5. **Revision extraction (RQ3)**\n",
        "   * From the **18,256 Copilot-generated PRs**, retrieved the full **edit history** of PR descriptions.\n",
        "   * Identified **1,437 revisions** where developers **edited the AI-suggested content**."
      ],
      "metadata": {
        "id": "j4dl0GKtyPQO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Toggle to TRUE to limit dataset, else process entire dataset\n",
        "TEST_MODE = True"
      ],
      "metadata": {
        "id": "Voi8T-6Z-U3t"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PXf5zM0UZf20",
        "outputId": "79beacb2-efd8-44f0-b446-6e16acb65f39"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATA_FOLDER = '/content/drive/MyDrive/AIDev_shared'\n",
        "if not os.path.exists(DATA_FOLDER):\n",
        "    os.makedirs(DATA_FOLDER)\n",
        "\n",
        "MODIFIER = '_TEST' if TEST_MODE else '_cleaned'\n",
        "\n",
        "METRICS_PKL = os.path.join(DATA_FOLDER, f'metrics${MODIFIER}.pkl')\n",
        "REPOS_PKL = os.path.join(DATA_FOLDER, f'repos${MODIFIER}.pkl')"
      ],
      "metadata": {
        "id": "F9yknfNQ-Z1C"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "eZ03WzKRQ1bS"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import matplotlib.pyplot as plt\n",
        "import nest_asyncio\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "from dateutil import parser\n",
        "from google.colab import userdata\n",
        "from urllib.parse import urlparse\n",
        "import time\n",
        "import random\n",
        "from itertools import cycle\n",
        "from google.colab import userdata\n",
        "from dateutil import parser\n",
        "from urllib.parse import urlparse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9b7c674"
      },
      "source": [
        "# **First**, Define the URLs of the AIDev Parquet Files that we are intersted in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de61a39b"
      },
      "source": [
        "pull_request_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/human_pull_request.parquet'\n",
        "pr_comments_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_comments.parquet'\n",
        "pr_commits_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_commits.parquet'\n",
        "pr_commit_details_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_commit_details.parquet'\n",
        "pr_reviews_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_reviews.parquet'\n",
        "pr_review_comments_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_review_comments.parquet'\n",
        "pr_task_type_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_task_type.parquet'\n",
        "repository_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/all_repository.parquet'\n",
        "user_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/user.parquet'"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Second**, We need to load the data from the URLs (15s)"
      ],
      "metadata": {
        "id": "CKy9xnAeb1p6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Parquet Files"
      ],
      "metadata": {
        "id": "eU0V6v6thrEQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Load the Parquet file into a Pandas DataFrame from the file URL.\n",
        "\"\"\"\n",
        "def load_data(url: str):\n",
        "  import pandas as pd # Import pandas inside the function\n",
        "  try:\n",
        "    # For Parquet files:\n",
        "    df = pd.read_parquet(url)\n",
        "\n",
        "    return df\n",
        "  except Exception as e:\n",
        "      print(f\"Error loading data: {e}\")\n",
        "      print(\"Please ensure the URL is correct and the file is publicly accessible.\")\n",
        "      return None # Return None in case of an error"
      ],
      "metadata": {
        "id": "Qcu3bdoFM6UE"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pull_request = load_data(pull_request_file_url)\n",
        "pr_comments = load_data(pr_comments_file_url)\n",
        "pr_commits = load_data(pr_commits_file_url)\n",
        "pr_commit_details = load_data(pr_commit_details_file_url)\n",
        "pr_reviews = load_data(pr_reviews_file_url)\n",
        "pr_review_comments = load_data(pr_review_comments_file_url)\n",
        "pr_task_type = load_data(pr_task_type_file_url)\n",
        "repository = load_data(repository_file_url)\n",
        "user = load_data(user_file_url)"
      ],
      "metadata": {
        "id": "YAPFfpktRJkz"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Copy of Pull_Requests & Data Cleaning\n",
        "\n",
        "1. **Copies DataFrames:** It creates copies of the pull_request and repository DataFrames and assigns them to metrics and repos respectively. This is a good practice to avoid modifying the original loaded data.\n",
        "2. **Renames Columns:** It renames the 'id' column to 'pr_id' in the metrics DataFrame and to 'repo_id' in the repos DataFrame. This is done to prepare for merging these DataFrames later.\n",
        "3. **Filters Open Pull Requests:** It removes pull requests that are still open by filtering out rows where the 'closed_at' column has a missing value (NaN).\n",
        "4. **Converts Timestamps:** It converts the 'created_at' and 'closed_at' columns in the metrics DataFrame to datetime objects. This allows for easier time-based calculations.\n",
        "5. **Filters Repositories:** It removes repositories from the repos DataFrame that do not have any closed pull requests in the metrics DataFrame.\n",
        "6. **Gets Repository Creation Dates:** For the remaining repositories, it calls the get_repo_created_at function (defined in a previous cell) to fetch the creation date of each repository from the GitHub API and stores it in a new column 'repo_created_at'.\n",
        "7. **Filters Repositories with Creation Dates:** It removes repositories where the 'repo_created_at' could not be retrieved."
      ],
      "metadata": {
        "id": "67cBtszBeJC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, time, random, requests, pandas as pd\n",
        "from datetime import datetime\n",
        "from itertools import cycle # Import cycle\n",
        "\n",
        "# Copy raw data\n",
        "metrics = pull_request.copy()\n",
        "repos = repository.copy()\n",
        "\n",
        "# === BASIC CLEANUP ===\n",
        "metrics = metrics.rename(columns={'id': 'pr_id'})\n",
        "repos = repos.rename(columns={'id': 'repo_id', 'url': 'repo_url'})\n",
        "\n",
        "print(f\"Total PRs before filtering: {len(metrics):,}\")\n",
        "metrics = metrics[metrics['closed_at'].notna()]\n",
        "metrics = pd.merge(metrics, repos[['repo_url','repo_id']], on='repo_url', how='left')\n",
        "metrics = metrics[metrics['repo_id'].notna()]\n",
        "print(f\"Closed PRs retained: {len(metrics):,}\")\n",
        "\n",
        "metrics['created_at'] = pd.to_datetime(metrics['created_at'], errors='coerce')\n",
        "metrics['closed_at'] = pd.to_datetime(metrics['closed_at'], errors='coerce')\n",
        "\n",
        "print(f\"Total repos before filtering: {len(repos):,}\")\n",
        "repos = repos[repos['repo_id'].isin(metrics['repo_id'])]\n",
        "print(f\"Repos with ≥1 PR: {len(repos):,}\")\n",
        "\n",
        "# === ADD: SMALL-SUBSET TEST MODE ===\n",
        "if TEST_MODE:\n",
        "    # Select the next 500 repos (from index 500 to 1000)\n",
        "    start_index = 500\n",
        "    end_index = 1000\n",
        "    if end_index > len(repos):\n",
        "        end_index = len(repos)\n",
        "        print(f\"[TEST MODE] Adjusting end index to {end_index} as it exceeds the number of repos.\")\n",
        "\n",
        "    test_repo_ids = repos['repo_id'].iloc[start_index:end_index]\n",
        "\n",
        "    metrics = metrics[metrics['repo_id'].isin(test_repo_ids)]\n",
        "    repos = repos[repos['repo_id'].isin(test_repo_ids)]\n",
        "    print(f\"[TEST MODE] Restricting to {len(repos)} repos and {len(metrics)} PRs (indices {start_index} to {end_index-1})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VKaF2xpBcvJd",
        "outputId": "0f07ba0c-6363-4c4e-8790-079ac4751ca8"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total PRs before filtering: 6,618\n",
            "Closed PRs retained: 6,129\n",
            "Total repos before filtering: 116,211\n",
            "Repos with ≥1 PR: 773\n",
            "[TEST MODE] Adjusting end index to 773 as it exceeds the number of repos.\n",
            "[TEST MODE] Restricting to 273 repos and 2572 PRs (indices 500 to 772)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save initial processed Dataset (no need to re-run this every time)"
      ],
      "metadata": {
        "id": "sVs4gjRhZ4zt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics.to_pickle(METRICS_PKL)\n",
        "repos.to_pickle(REPOS_PKL)"
      ],
      "metadata": {
        "id": "WOunph6PZrOq"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reload dataset (this can be ran every time)"
      ],
      "metadata": {
        "id": "YUGl3g1aaApG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "metrics = pd.read_pickle(METRICS_PKL)\n",
        "repos = pd.read_pickle(REPOS_PKL)\n",
        "print('✅ Loaded shared cached dataset')"
      ],
      "metadata": {
        "id": "KxAKR0tjaA7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "08d8d592-c0d1-4c3f-bef0-969c3074ae55"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded shared cached dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Third**, Gather the covariant variables\n",
        "\n",
        "## PR Variables\n",
        "\n",
        "1. **additions:** The # of added LOC by a PR\n",
        "2. **deletions:** The # of deleted LOC by a PR\n",
        "3. **prSize:** The total number of added and deleted LOC by a PR (additions + deletions)\n",
        "4. **purpose:** The purpose of a PR, i.e., bug, document, and feature. Simple keyword search in the title/body ('fix', 'bug', 'doc', …).\n",
        "5. **changedFiles:** The # of files changed by a PR\n",
        "6. **commitsTotalCount:** The # of commits involved in a PR\n",
        "7. **bodyLength**: Length of the PR body (in characters).\n",
        "8. **prExperience:** The # of prior PRs that were submitted by the PR author (author’s prior PR count). Query the author’s PR history in the same repo and count PRs created before the current one.\n",
        "9. **commentsTotalCount:** The # of comments left on a PR\n",
        "10. **authorComments:** The # of comments left by the PR author\n",
        "11. **reviewersComments:** The # of comments left by the reviewers who participate in the disucssion\n",
        "12. **reviewersTotalCount:** The # of developers who participate in the discussion (excluding author).\n",
        "13. **repoAge:** Time interval between the repository creation time and PR creation time in days.\n",
        "14. **isMember:** Whether or not the author is a member or outside collaborator (True/False).\n",
        "15. **state**: State of the pull request (MERGED or CLOSED).\n",
        "16. **reviewTime**: Time taken to review the PR (in hours, floating point, no rounding).\n",
        "\n",
        "## Project variables\n",
        "\n",
        "17. **repoLanguage:** Programming language of the repository (e.g., Python, PHP, TypeScript, Vue). *[I'm assuming its the top language as there is only one]*\n",
        "18. **forkCount:** The # of forks that a repository has\n",
        "19. **stargazerCount:** The # of stargazers that a repository has.\n",
        "\n",
        "## Treatment variables\n",
        "\n",
        "20. **With Copilot for PRs:** Whether or not a PR is generated by Copilot for PRs (binary)\n",
        "\n",
        "## Outcome variables\n",
        "\n",
        "21. **Review time (reviewTime):** Time interval between the PR creation time and closed time in hours\n",
        "22. **Is merged (state):** Whether or not a PR is merged (binary)\n",
        "\n"
      ],
      "metadata": {
        "id": "a30SFFhZXgy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PR Variables"
      ],
      "metadata": {
        "id": "xANcFKyCb9Fm"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34d51076"
      },
      "source": [
        "1. **additions:** The # of added LOC by a PR\n",
        "2. **deletions:** The # of deleted LOC by a PR\n",
        "3. **prSize:** The total number of added and deleted LOC by a PR (additions + deletions)\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "In the notebook (e.g., CollectCopilot4prs.ipynb), the `additions` and `deletions` values are extracted directly from the GitHub API response for each PR: `pr['node']['additions']` and `pr['node']['deletions']`. The GraphQL query for PRs includes the fields, so the value is as reported by GitHub. `prSize = additions + deletions`\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "In the `pr_commit_details` DataFrame, we use the `additions` and `deletions` fields. We sum them for `prSize`. Alternatively, the dataset also has`changes` which represents prSize but we chose to perform the sum ourselves.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['additions', 'deletions', 'prSize'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding LOC metrics: {len(metrics):,}\")\n",
        "\n",
        "# Get the sums of the columns we are interested in\n",
        "pr_commit_LOC = (pr_commit_details.groupby(['pr_id'])\n",
        "                                  .sum(['additions', 'deletions', 'changes'])\n",
        "                                  .reset_index())\n",
        "\n",
        "# Rename the sum columns to what we want\n",
        "pr_commit_LOC = (pr_commit_LOC.rename(columns={'changes': 'prSize'}))\n",
        "\n",
        "# Drop the extraneous columns\n",
        "pr_commit_LOC = pr_commit_LOC.drop(columns=['commit_stats_total', 'commit_stats_additions', 'commit_stats_deletions'])\n",
        "\n",
        "# Merge the Dataframes with a left join\n",
        "metrics = pd.merge(metrics, pr_commit_LOC, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage collect the temporary Dataframe\n",
        "pr_commit_LOC = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['additions'] = metrics['additions'].fillna(0).astype(int)\n",
        "metrics['deletions'] = metrics['deletions'].fillna(0).astype(int)\n",
        "metrics['prSize'] = metrics['prSize'].fillna(0).astype(int)\n",
        "\n",
        "print(f\"Number of PRs after adding LOC metrics: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "nj9typbGIcI2",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b73017d4-3352-4f28-c119-26634a3e90ad"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding LOC metrics: 2,572\n",
            "Number of PRs after adding LOC metrics: 2,572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **purpose:** The purpose of a PR, i.e., bug, document, and feature. Simple keyword search in the title/body ('fix', 'bug', 'doc', …).\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "In `CollectCopilot4prs.ipynb`, the code uses `np.select` with conditions based on the PR's title and body content to assign \"Bug\", \"Document\", or \"Feature\" as the purpose. This is a simple rule-based classification:\n",
        "\n",
        "- If the title/body contains keywords for bugs (e.g., \"fix\", \"bug\"), it's labeled \"Bug\".\n",
        "- If it contains documentation keywords (e.g., \"doc\"), it's labeled \"Document\".\n",
        "- Otherwise, it's labeled \"Feature\".\n",
        "\n",
        "\n",
        "**Our approach:**\n",
        "\n",
        "The `title` and `body` columns are part of the initial dataset that was loaded into the pull_request (`all_pull_request.parquet`) DataFrame.\n"
      ],
      "metadata": {
        "id": "_9ULLRD1eVyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['purpose'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before calculating purpose: {len(metrics):,}\")\n",
        "\n",
        "# Combine title and body for keyword search, handling potential None values\n",
        "metrics['title_body'] = metrics['title'].fillna('') + ' ' + metrics['body'].fillna('')\n",
        "\n",
        "# Define conditions and choices for np.select\n",
        "conditions = [\n",
        "    metrics['title_body'].str.contains('fix|bug', case=False, na=False),\n",
        "    metrics['title_body'].str.contains('doc', case=False, na=False)\n",
        "]\n",
        "choices = ['fix', 'doc']\n",
        "\n",
        "# Apply np.select to determine purpose\n",
        "metrics['purpose'] = np.select(conditions, choices, default='feat')\n",
        "\n",
        "# Drop the temporary combined column\n",
        "metrics = metrics.drop(columns=['title_body'])\n",
        "\n",
        "print(f\"Number of PRs after calculating purpose: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "Hc2sYaVwFPdL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1079d31d-3791-437c-81a2-f980f19dba26"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before calculating purpose: 2,572\n",
            "Number of PRs after calculating purpose: 2,572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c02810ce"
      },
      "source": [
        "5. **changedFiles:** The # of files changed by a PR\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "The `changedFiles` field is extracted directly from the GitHub API for each pull request. In the code (e.g., `in CollectCopilot4prs.ipynb`), it is accessed as: `pr['node']['changedFiles']`.\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "\n",
        "This variable is calculated from the `pr_commit_details` DataFrame, steps include:\n",
        "\n",
        "- Identify the PR ID: The code uses `groupby(['pr_id', 'filename'])` which implicitly identifies each PR by its `pr_id`.\n",
        "- Locate the file-level change records: It operates on the `pr_commit_details` DataFrame, which contains the file-level change records.\n",
        "- Collect all rows belonging to the same PR: The `groupby(['pr_id', 'filename'])` operation groups all rows for a specific PR together.\n",
        "- Count the number of unique filenames for each `pr_id` across all its commits."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['changedFiles'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding changedFiles: {len(metrics):,}\")\n",
        "\n",
        "# Count the number of Files changed and change the column name to what we want\n",
        "pr_files_changed = (pr_commit_details.groupby(['pr_id', 'filename'])\n",
        "                                     .size()\n",
        "                                     .groupby(['pr_id'])\n",
        "                                     .size()\n",
        "                                     .reset_index(name='changedFiles'))\n",
        "\n",
        "# Merge the Dataframes with a left join\n",
        "metrics = pd.merge(metrics, pr_files_changed, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframe\n",
        "pr_files_changed = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['changedFiles'] = metrics['changedFiles'].fillna(0).astype(int)\n",
        "\n",
        "print(f\"Number of PRs after adding changedFiles: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "YwnUjWn9FPY3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c198136-0868-43d8-8c0a-2e0304d3bfdc"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding changedFiles: 2,572\n",
            "Number of PRs after adding changedFiles: 2,572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **commitsTotalCount:** The # of commits involved in a PR\n",
        "\n",
        "\n",
        "**Xiao, 2024:**\n",
        "\n",
        "Fetched from GitHub’s GraphQL API by querying the PR’s `commits { totalCount }` field.\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "The `pr_commit_details` table contains a `sha` column (the commit hash) and a `pr_id` column that links each commit to its pull request. Count every distinct `sha` in the entire table. Group by `pr_id` and count distinct `sha` values for each group.\n"
      ],
      "metadata": {
        "id": "xxZIoTx8fiCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['commitsTotalCount'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding commitsTotalCount: {len(metrics):,}\")\n",
        "\n",
        "# Calculate the number of unique commits for each Pull Request from pr_commit_details\n",
        "# Group by pr_id and count the number of unique sha values\n",
        "pr_commits_count = pr_commit_details.groupby('pr_id')['sha'].nunique().reset_index(name='commitsTotalCount')\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, pr_commits_count, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframe\n",
        "pr_commits_count = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['commitsTotalCount'] = metrics['commitsTotalCount'].fillna(0).astype(int)\n",
        "\n",
        "print(f\"Number of PRs after adding commitsTotalCount: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "vOyzUxnHFPUc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6021005-9d37-42a2-9903-6054e21d0dc8"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding commitsTotalCount: 2,572\n",
            "Number of PRs after adding commitsTotalCount: 2,572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **bodyLength:** The length of a PR description\n",
        "\n",
        "**Xiao, 2024:**\n",
        "\n",
        "Query each PR with `pullRequest { body }`. Take the returned text and compute its character count (e.g., len(body)). Record that count as the value of description length.\n",
        "\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "In the `pull_request` DataFrame, calculate the character length of the `body` column.\n"
      ],
      "metadata": {
        "id": "Ed6fS14afxfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['bodyLength'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding bodyLength: {len(metrics):,}\")\n",
        "\n",
        "# Get the Length of the Body of the Pull Request\n",
        "metrics['bodyLength'] = metrics['body'].str.len()\n",
        "\n",
        "print(f\"Number of PRs after adding bodyLength: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "OZYyz-mVFPPp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ba5e879-c73e-4602-dea5-01a012874394"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding bodyLength: 2,572\n",
            "Number of PRs after adding bodyLength: 2,572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. **prExperience:** The # of prior PRs that were submitted by the PR author (author’s prior PR count). Query the author’s PR history in the same repo and count PRs created before the current one.\n",
        "\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "For every pull request the study queries GitHub’s GraphQL API and extracts the author.login (or author.id) and the repository identifier (repository.id). Using the same API they request all pull requests belonging to the same repository.id whose author.login matches the author of the target PR. Each of these PRs includes its createdAt timestamp. The list is filtered to keep only those PRs whose createdAt value is earlier than the createdAt timestamp of the target PR. The number of remaining PRs is taken as an integer count.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "- Extract the author's login from the `user` column.\n",
        "- Sorts the metrics DataFrame by `repo_id`, `author_login`, and the PR creation time (`created_at`).\n",
        "- Groups the sorted DataFrame by both `repo_id` and `author_login`.\n",
        "- Within each group (for each unique author in each unique repository), it uses the `.cumcount()` method. `cumcount()` assigns a sequential number starting from 0 to each row within the group based on the current order (which is sorted by `created_at`).\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JQyVdlFCf2yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['prExperience'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding prExperience: {len(metrics):,}\")\n",
        "\n",
        "# Extract the author's login from the 'user' column and store it in a new column 'author_login'\n",
        "metrics['author_login'] = metrics['user'].astype(str).str.strip()\n",
        "\n",
        "# Drop rows where 'repo_id' or 'created_at' are missing, as these are needed for sorting and calculation\n",
        "metrics = metrics.dropna(subset=['repo_id', 'created_at'])\n",
        "\n",
        "# Sort the DataFrame by 'repo_id', 'author_login', and 'created_at' in ascending order--This is crucial for correctly calculating the cumulative count of PRs for each author within each repository.\n",
        "metrics = metrics.sort_values(['repo_id', 'author_login', 'created_at'])\n",
        "\n",
        "# Calculate the cumulative count of PRs for each author within each repository.\n",
        "# The `groupby(['repo_id', 'author_login'])` groups the DataFrame by repository and author.\n",
        "# The `cumcount()` method then calculates the number of previous PRs for each row within those groups.\n",
        "metrics['prExperience'] = (\n",
        "    metrics.groupby(['repo_id', 'author_login'])\n",
        "           .cumcount()\n",
        "           .astype('Int64')\n",
        ")\n",
        "\n",
        "print(f\"Number of PRs after adding bodyLength: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "iS8q-30-icdf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29aa7492-4a86-4702-8280-f8e5c7c898dd"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding prExperience: 2,572\n",
            "Number of PRs after adding bodyLength: 2,572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. **commentsTotalCount:** The # of comments left on a PR\n",
        "\n",
        "\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "`commentsTotalCount` is obtained directly from the GitHub GraphQL API. For each pull request it queries the PR’s `comments` connection and records the `totalCount` field, which is the number of comment objects attached to that PR (including review comments, issue‑style comments, and any other discussion entries).\n",
        "\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "Group the `pr_comments` DataFrame by `pr_id` (Pull Request ID). Each row in `pr_comments` represents a single comment.\n",
        "Count the number of rows within each group using `.size()`.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ac9ifXkVgLqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (rentrant code)\n",
        "metrics.drop(columns=['commentsTotalCount'], errors='ignore', inplace=True)\n",
        "\n",
        "print(f\"Number of PRs before adding commentsTotalCount: {len(metrics):,}\")\n",
        "\n",
        "# Count the number of Comments for the Pull Request, name the column what we want.\n",
        "pr_comments_count = pr_comments.groupby(['pr_id']).size().reset_index(name='commentsTotalCount')\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, pr_comments_count, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframe\n",
        "pr_comments_count = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['commentsTotalCount'] = metrics['commentsTotalCount'].fillna(0).astype(int)\n",
        "\n",
        "print(f\"Number of PRs after adding commentsTotalCount: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "2BNmsnGIFO9Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26de0859-579b-4bc3-c7a1-748e16afda8c"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding commentsTotalCount: 2,572\n",
            "Number of PRs after adding commentsTotalCount: 2,572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. **authorComments:** The # of comments left by the PR author\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "Query each PR’s comment data through the GitHub GraphQL API and then filter the comment list to keep only those whose `author.login` matches the PR author’s login.\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "Merges `pr_comments` with author information and counting comments where the comment author matches the PR author."
      ],
      "metadata": {
        "id": "LoBAgwxOgaJn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "322b4128",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bab09646-6513-4551-a60e-5c81213bf91f"
      },
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['authorComments'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding authorComments: {len(metrics):,}\")\n",
        "\n",
        "# Filter comments to only include those made by the PR author\n",
        "# Need to merge with metrics to get the author_id for each pr_comment\n",
        "author_comments = pd.merge(pr_comments, metrics[['pr_id', 'user_id']], left_on='pr_id', right_on='pr_id', how='left')\n",
        "author_comments = author_comments[author_comments['user_id_x'] == author_comments['user_id_y']]\n",
        "\n",
        "# Count the number of author comments per pull request\n",
        "author_comments_count = author_comments.groupby(['pr_id']).size().reset_index(name='authorComments')\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, author_comments_count, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframes\n",
        "author_comments = None\n",
        "author_comments_count = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['authorComments'] = metrics['authorComments'].fillna(0).astype(int)\n",
        "\n",
        "print(f\"Number of PRs after adding authorComments: {len(metrics):,}\")"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding authorComments: 2,572\n",
            "Number of PRs after adding authorComments: 2,572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. **reviewersComments:** The # of comments left by the reviewers who participate in the disucssion\n",
        "\n",
        "\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "Querying the `comments` edge of each PR via GraphQL (or the REST endpoint `GET /repos/{owner}/{repo}/issues/{pull_number}/comments`). Filtering out comments whose user.login equals the PR author’s login. Counting the remaining comments – that number is the reviewerComments value.\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "Merges `pr_comments` with author information and counting comments where the comment author does not match the PR author.\n",
        "\n"
      ],
      "metadata": {
        "id": "0cC_Qh-DgvEJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "454479f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04d3403b-e319-46d8-c15c-d88cbc0fdf9b"
      },
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['reviewersComments'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding reviewersComments: {len(metrics):,}\")\n",
        "\n",
        "# Filter comments to exclude those made by the PR author\n",
        "# Need to merge with metrics to get the author_id for each pr_comment\n",
        "reviewer_comments = pd.merge(pr_comments, metrics[['pr_id', 'user_id']], left_on='pr_id', right_on='pr_id', how='left')\n",
        "reviewer_comments = reviewer_comments[reviewer_comments['user_id_x'] != reviewer_comments['user_id_y']]\n",
        "\n",
        "# Count the number of reviewer comments per pull request\n",
        "reviewer_comments_count = reviewer_comments.groupby(['pr_id']).size().reset_index(name='reviewersComments')\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, reviewer_comments_count, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframes\n",
        "reviewer_comments = None\n",
        "reviewer_comments_count = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['reviewersComments'] = metrics['reviewersComments'].fillna(0).astype(int)\n",
        "\n",
        "print(f\"Number of PRs after adding reviewersComments: {len(metrics):,}\")"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding reviewersComments: 2,572\n",
            "Number of PRs after adding reviewersComments: 2,572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. **reviewersTotalCount:** The # of developers who participate in the discussion (excluding author).\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "Calling the GraphQL endpoint for each PR,\n",
        "Requesting the `reviewers` (or `reviewRequests`) connection,\n",
        "Reading the `totalCount` field,\n",
        "Verifying that the author’s login is excluded (or simply using the `totalCount` as GitHub already excludes the author in the `reviewers` connection).\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "Calculates `reviewersTotalCount` by summing the counts of unique reviewers from reviews (`reviewers`) for each pull request.\n",
        "\n"
      ],
      "metadata": {
        "id": "sDtcHmxxg9MP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b294946",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "outputId": "8e1fa714-87f0-443e-de19-354ad53e1ab8"
      },
      "source": [
        "# Ensure we don't crash if columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['reviewersTotalCount'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding reviewersTotalCount: {len(metrics):,}\")\n",
        "\n",
        "# Create a copy of PR reviews with only the necessary columns\n",
        "pr_reviews_temp = pr_reviews.copy().drop(columns=['id', 'state', 'submitted_at', 'body', 'user_type'], errors='ignore')\n",
        "\n",
        "# Filter reviews to exclude those made by the PR author\n",
        "# Merge with metrics to get the author_id for each pr_comment\n",
        "pr_reviews_temp = pd.merge(pr_reviews_temp, metrics[['pr_id', 'user']], left_on='pr_id', right_on='pr_id', how='left')\n",
        "pr_reviews_temp = pr_reviews_temp[pr_reviews_temp['user_x'] != pr_reviews_temp['user_y']]\n",
        "\n",
        "# Count the number of unique non-author users who left review comments per pull request\n",
        "# Group by 'pr_id' to count per pull request\n",
        "pr_reviews_temp = pr_reviews_temp.groupby(['pr_id'])['user_x'].nunique().reset_index(name='reviewersTotalCount')\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, pr_reviews_temp, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframes\n",
        "pr_reviews_temp = None\n",
        "\n",
        "# Fill N/A values with defaults (for PRs with no reviews/comments)\n",
        "metrics['reviewersTotalCount'] = metrics['reviewersTotalCount'].fillna(0).astype(int)\n",
        "\n",
        "print(f\"Number of PRs after adding reviewersTotalCount: {len(metrics):,}\")\n",
        "\n",
        "\n",
        "# Display unique values and their counts for 'reviewersTotalCount'\n",
        "print(\"\\nUnique values and counts for 'reviewersTotalCount':\")\n",
        "display(metrics['reviewersTotalCount'].value_counts(dropna=False).sort_index())"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding reviewersTotalCount: 2,572\n",
            "Number of PRs after adding reviewersTotalCount: 2,572\n",
            "\n",
            "Unique values and counts for 'reviewersTotalCount':\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "reviewersTotalCount\n",
              "0    2572\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>reviewersTotalCount</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2572</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. **repoAge:** Time interval between the repository creation time and PR creation time in days.\n",
        "\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "- Retrieve the creation timestamp of the repository (the time the repo was first created on GitHub).\n",
        "- Retrieve the creation timestamp of the pull request under study.\n",
        "- Compute the time interval between these two timestamps in days\n",
        "\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "\n",
        "Separate Process\n"
      ],
      "metadata": {
        "id": "Bvwr_F_0h3p-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics['repoAge'] = 0"
      ],
      "metadata": {
        "id": "2F_B8cSbOFYH"
      },
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. **isMember:** Whether or not the author is a member or outside collaborator (True/False).\n",
        "\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "- For each PR the study calls GitHub’s GraphQL API and retrieves the author’s association with the repository (the `authorAssociation` field).\n",
        "- If the returned association is `MEMBER` or `OWNER`, the flag is set to 1; otherwise (e.g., `CONTRIBUTOR`, `NONE`, or an external collaborator) it is set to 0.\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "Followed the same approach as Xiao 2024."
      ],
      "metadata": {
        "id": "IhSC6qwXf95V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics['isMember'] = False"
      ],
      "metadata": {
        "id": "ww7_i5LlNnWV"
      },
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. **state**: State of the pull request (MERGED or CLOSED).\n",
        "\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "In GitHub GraphQL (or REST) API, the response includes a field called state (or, equivalently, a Boolean merged flag). The value of that field can be one of three mutually‑exclusive statuses:\n",
        "- MERGED (or merged = true)\tThe PR was successfully merged into the target branch.\n",
        "- CLOSED (or merged = false & state = CLOSED)\tThe PR was closed without being merged.\n",
        "- OPEN (or state = OPEN)\tThe PR was still open at the time the data were collected.\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "If the `merged_at` column for a pull request has a value (i.e., it's not `null`), it means the pull request was merged, and the state is set to `MERGED`.\n",
        "If the `merged_at` column is `null`, it means the pull request was closed without being merged, and the state is set to `CLOSED`.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qNQdfoY8iNBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['state'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding state: {len(metrics):,}\")\n",
        "\n",
        "# Set the State to MERGED or CLOSED\n",
        "metrics['state'] = metrics['merged_at'].apply(lambda x: 'MERGED' if x is not None else 'CLOSED')\n",
        "\n",
        "print(f\"Number of PRs after adding state: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "5Ftmm7qZlHbW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d0f9cc9-c1e4-4a7e-9bb7-62d708596f04"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding state: 2,572\n",
            "Number of PRs after adding state: 2,572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "16. **reviewTime**: Time taken to review the PR (in hours, floating point, no rounding).\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "`reviewtime` (in hours) = (PR Closed Timestamp - PR Creation Timestamp).\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "The difference between the `closed_at` and `created_at` timestamps and converting that duration into hours.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "VzgXfZtoCjPS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['reviewTime'], errors='ignore')\n",
        "\n",
        "print(f\"Number of PRs before adding reviewTime: {len(metrics):,}\")\n",
        "\n",
        "# Calculate the Review Time\n",
        "metrics['reviewTime'] = (metrics['closed_at'] - metrics['created_at']).dt.total_seconds() / 3600\n",
        "\n",
        "print(f\"Number of PRs after adding reviewTime: {len(metrics):,}\")"
      ],
      "metadata": {
        "id": "UM0zn7ZtCmdr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3138a909-9042-4501-f9be-bf9ad1221e16"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of PRs before adding reviewTime: 2,572\n",
            "Number of PRs after adding reviewTime: 2,572\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project variables"
      ],
      "metadata": {
        "id": "1unf8guqcK2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17. **repoLanguage:** Programming language of the repository (e.g., Python, PHP, TypeScript, Vue).\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "The number of stargazers that a repository has\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "Same approach\n",
        "\n",
        "\n",
        "18. **forkCount:** The # of forks that a repository has\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "\n",
        "19. **stargazerCount:** The # of stargazers that a repository has.\n",
        "\n",
        "**Xiao 2024:**\n",
        "\n",
        "\n",
        "**Our Approach:**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "A5lSM-5VimJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['repoLanguage', 'forkCount', 'stargazerCount'], errors='ignore')\n",
        "\n",
        "repos_temp = (repos.copy()\n",
        "                   .drop(columns=['license', 'repo_url', 'html_url', 'full_name'], errors='ignore')\n",
        "                   .rename(columns={'language': 'repoLanguage', 'forks': 'forkCount', 'stars': 'stargazerCount'}))\n",
        "\n",
        "# Group by ID and get the First Record\n",
        "repos_temp = repos_temp.groupby(['repo_id']).first().reset_index() # Add reset_index() to make repo_id a column again\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, repos_temp, left_on='repo_id', right_on='repo_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframe\n",
        "repos_temp = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['repoLanguage'] = metrics['repoLanguage'].fillna('other')\n",
        "metrics['forkCount'] = metrics['forkCount'].fillna(0).astype(int)\n",
        "metrics['stargazerCount'] = metrics['stargazerCount'].fillna(0).astype(int)"
      ],
      "metadata": {
        "id": "hEoTBBXjFOVZ"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treatment variables"
      ],
      "metadata": {
        "id": "RV-ykVvwcSGJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. **With Copilot for PRs:** Whether or not a PR is generated by Copilot for PRs (binary)\n"
      ],
      "metadata": {
        "id": "zUDj9SFMjShm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (rentrant code)\n",
        "metrics = metrics.drop(columns=['isGeneratedByCopliot'], errors='ignore')\n",
        "\n",
        "metrics['isGeneratedByCopilot'] = metrics['agent'].apply(lambda x: True if x == 'Copilot' else False) # Corrected column name and capitalization"
      ],
      "metadata": {
        "id": "btn7vVCnjSTb"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outcome variables"
      ],
      "metadata": {
        "id": "iRzFbe-Acwbw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. **Review time (reviewTime):** Time interval between the PR creation time and closed time in hours\n"
      ],
      "metadata": {
        "id": "0Nzqcx6Yi6Uo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61c5c683",
        "collapsed": true
      },
      "source": [
        "# Make sure we don't crash because the columns already exist (rentrant code)\n",
        "metrics = metrics.drop(columns=['reviewTime'], errors='ignore')\n",
        "\n",
        "# Calculate review time in hours, handling potential NaT values\n",
        "metrics = metrics.assign(reviewTime=lambda x: (x['closed_at'] - x['created_at']).dt.total_seconds() / 3600)\n",
        "\n",
        "# Fill N/A values with defaults (e.g., for open PRs)\n",
        "metrics['reviewTime'] = metrics['reviewTime'].fillna(0)"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. **Is merged (state):** Whether or not a PR is merged (binary)\n"
      ],
      "metadata": {
        "id": "-QSkr74njEzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['isMerged'], errors='ignore')\n",
        "\n",
        "# If Merged_At is None, the PR was not merged, otherwise it was\n",
        "metrics['isMerged'] = metrics['merged_at'].apply(lambda x: 0 if x is None else 1)"
      ],
      "metadata": {
        "id": "fvl0rnKHbOwd"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Order in CSV (control_metrics.csc)\n",
        "\n",
        "1. **repoLanguage**\n",
        "2. **forkCount**\n",
        "3. **stargazerCount**\n",
        "4. **repoAge**\n",
        "5. **state**\n",
        "6. **deletions**\n",
        "7. **additions**\n",
        "8. **changedFiles**\n",
        "9. **commentsTotalCount**\n",
        "10. **commitsTotalCount**\n",
        "11. **prExperience**\n",
        "12. **isMember**\n",
        "13. **authorComments**\n",
        "14. **reviewersComments**\n",
        "15. **reviewersTotalCount**\n",
        "16. **bodyLength**\n",
        "17. **prSize**\n",
        "18. **reviewTime**\n",
        "19. **purpose**\n"
      ],
      "metadata": {
        "id": "0-kgS2O2dL6I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Export to CSV"
      ],
      "metadata": {
        "id": "3z7NwYwGxxiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the desired order of columns for the output CSVs\n",
        "csv_order = ['repoLanguage',\n",
        "'forkCount',\n",
        "'stargazerCount',\n",
        "'repoAge',\n",
        "'state',\n",
        "'deletions',\n",
        "'additions',\n",
        "'changedFiles',\n",
        "'commentsTotalCount',\n",
        "'commitsTotalCount',\n",
        "'prExperience',\n",
        "'isMember',\n",
        "'authorComments',\n",
        "'reviewersComments',\n",
        "'reviewersTotalCount',\n",
        "'bodyLength',\n",
        "'prSize',\n",
        "'reviewTime',\n",
        "'purpose']\n",
        "\n",
        "# Split the metrics DataFrame into control (non-Copilot) based on the 'isGeneratedByCopilot' column\n",
        "try:\n",
        "    # Use the isGeneratedByCopilot column for splitting\n",
        "    control_metrics_full = metrics[metrics['isGeneratedByCopilot'] == False].copy()\n",
        "except KeyError:\n",
        "    print(\"Error: 'isGeneratedByCopilot' column not found in metrics DataFrame. Please ensure it's included in previous steps.\")\n",
        "    raise\n",
        "\n",
        "# Select and reorder columns for the treatment and control DataFrames\n",
        "control_metrics = control_metrics_full[csv_order].copy()\n",
        "\n",
        "# Now, drop rows with NaN values from the column-filtered DataFrames\n",
        "print(f\"Number of control PRs before dropping NaNs: {len(control_metrics):,}\")\n",
        "control_metrics.dropna(inplace=True)\n",
        "print(f\"Number of control PRs after dropping NaNs: {len(control_metrics):,}\")\n",
        "\n",
        "# Define the file paths\n",
        "control_file_path = os.path.join(DATA_FOLDER, \"control_metrics.csv\")\n",
        "\n",
        "# Export to CSV\n",
        "control_metrics.to_csv(control_file_path, index=False)\n",
        "\n",
        "print(f\"✅ Exported control metrics to: {control_file_path}\")"
      ],
      "metadata": {
        "id": "ov2O_pNGwy-3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d1cf24f-d641-4f8d-abfc-0b3b8b4a1cef"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of control PRs before dropping NaNs: 2,572\n",
            "Number of control PRs after dropping NaNs: 2,134\n",
            "✅ Exported control metrics to: /content/drive/MyDrive/AIDev_shared/control_metrics.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fourth**, Bot detection and filtering employed the methodology of Golzadeh et al. (2022)\n",
        "\n",
        "simple “bot” username suffix check with a comprehensive, manually verified list of 527 bot accounts\n",
        "* groundtruthbots.csv - a list of bots from Golzadeh et al.\n"
      ],
      "metadata": {
        "id": "V8vXCVjGW1aV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "# Define the file path for the ground truth bots list (now a CSV)\n",
        "bots_file_path = os.path.join(DATA_FOLDER, \"groundtruthbots.csv\")\n",
        "\n",
        "# Load the ground truth bots list from CSV\n",
        "try:\n",
        "    # Assuming the CSV has a header and the usernames are in the first column\n",
        "    groundtruth_bots_df = pd.read_csv(bots_file_path)\n",
        "    # Extract the first column and convert to a list, handling potential NaNs\n",
        "    groundtruth_bots = groundtruth_bots_df.iloc[:, 0].dropna().astype(str).tolist()\n",
        "    print(f\"Loaded {len(groundtruth_bots)} bot usernames from {bots_file_path}\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: {bots_file_path} not found. Please ensure the file exists and contains bot usernames in the first column.\")\n",
        "    groundtruth_bots = [] # Initialize as empty list to avoid errors later\n",
        "except Exception as e:\n",
        "    print(f\"An error occurred while reading {bots_file_path}: {e}\")\n",
        "    groundtruth_bots = [] # Initialize as empty list\n",
        "\n",
        "\n",
        "# --- Filter bot-submitted PRs from metrics DataFrame ---\n",
        "\n",
        "print(f\"Number of PRs before bot filtering: {len(metrics):,}\")\n",
        "\n",
        "# Filter out PRs where the author's login ends with 'bot' or is in the ground truth list\n",
        "# Ensure 'author_login' column exists and is treated as string\n",
        "if 'author_login' not in metrics.columns:\n",
        "    print(\"Warning: 'author_login' column not found in metrics. Skipping PR bot filtering.\")\n",
        "    # You might want to add a step to create 'author_login' here if it's missing\n",
        "    # For now, we'll skip this filtering step to avoid crashing\n",
        "    metrics_filtered = metrics.copy()\n",
        "else:\n",
        "    metrics_filtered = metrics[\n",
        "        (~metrics['author_login'].astype(str).str.lower().str.endswith('bot', na=False)) &\n",
        "        (~metrics['author_login'].astype(str).isin(groundtruth_bots))\n",
        "    ].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "\n",
        "\n",
        "print(f\"Number of PRs after bot filtering: {len(metrics_filtered):,}\")\n",
        "\n",
        "\n",
        "# --- Filter bot comments from pr_comments DataFrame ---\n",
        "\n",
        "print(f\"Number of comments before bot filtering: {len(pr_comments):,}\")\n",
        "\n",
        "# Filter out comments where the user's login ends with 'bot' or is in the ground truth list\n",
        "# Ensure 'user' column exists and is treated as string\n",
        "if 'user' not in pr_comments.columns:\n",
        "     print(\"Warning: 'user' column not found in pr_comments. Skipping comment bot filtering.\")\n",
        "     # You might want to add a step to create 'user' here if it's missing\n",
        "     # For now, we'll skip this filtering step to avoid crashing\n",
        "     pr_comments_filtered = pr_comments.copy()\n",
        "else:\n",
        "    pr_comments_filtered = pr_comments[\n",
        "        (~pr_comments['user'].astype(str).str.lower().str.endswith('bot', na=False)) &\n",
        "        (~pr_comments['user'].astype(str).isin(groundtruth_bots))\n",
        "    ].copy() # Use .copy() to avoid SettingWithCopyWarning\n",
        "\n",
        "\n",
        "print(f\"Number of comments after bot filtering: {len(pr_comments_filtered):,}\")\n",
        "\n",
        "# You can now replace the original metrics and pr_comments DataFrames with the filtered ones\n",
        "metrics = metrics_filtered\n",
        "pr_comments = pr_comments_filtered\n",
        "\n",
        "print(\"Bot filtering applied to metrics and pr_comments DataFrames.\")"
      ],
      "metadata": {
        "id": "AqXYcUmgxz1z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ff201f3-33e4-409f-f1bb-113e33579025"
      },
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 5000 bot usernames from /content/drive/MyDrive/AIDev_shared/groundtruthbots.csv\n",
            "Number of PRs before bot filtering: 2,572\n",
            "Number of PRs after bot filtering: 2,538\n",
            "Number of comments before bot filtering: 39,122\n",
            "Number of comments after bot filtering: 38,381\n",
            "Bot filtering applied to metrics and pr_comments DataFrames.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fifth**, Adoption Trend (RQ1)\n",
        "(RQ1) To what extent do developers use Copilot for PRs in the code review process?\n",
        "\n",
        "* Counted occurrences of each marker tag; copilot:summary was the most frequent (13 231 instances).\n",
        "* Visualised cumulative PRs over time (Fig. 3) and proportion of PRs per repository (Fig. 4).\n"
      ],
      "metadata": {
        "id": "g4l6_AqBzYVI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CNLP973ZzYBt"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sixth**, Causal Inference (RQ2)\n",
        "\n",
        "### Propensity‑Score Estimation\n",
        "Logistic regression (treatment = Copilot usage) on the 17 covariates.\n",
        "Estimated each PR’s probability of receiving the treatment (ps).\n",
        "### Weight Construction\n",
        "Inverse‑probability weights: 1/ps for treated, 1/(1‑ps) for control.\n",
        "### Entropy Balancing\n",
        "Applied the entropy‑balancing algorithm (equivalent to R’s ebalance) to adjust the raw weights so that the weighted means of all covariates matched exactly between groups.\n",
        "After balancing, absolute mean differences for every covariate were ≤ 0.10 (Fig. 2).\n",
        "### Outcome Regression\n",
        "* Review time (continuous): weighted ordinary least squares (lm analogue) with only the treatment indicator. The coefficient gave the Average Treatment Effect on the Treated (ATT) of ‑19.3 h (p ≈ 1.6 × 10⁻¹⁷).\n",
        "* Merge outcome (binary): weighted logistic regression (glm with logit link). The exponentiated treatment coefficient yielded an odds ratio of 1.57 (95 % CI [1.35, 1.84], p < 0.001).\n",
        "These two models answer RQ2.1 (review‑time reduction) and RQ2.2 (higher merge likelihood).\n"
      ],
      "metadata": {
        "id": "48T4d5AezoVx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The R Scripts\n",
        "The main difference between PMW_merge.R and PMW_review.R is:\n",
        "\n",
        "* PMW_merge.R includes the column isMerged, which indicates whether each pull request was merged (state == \"MERGED\"). This column is added to the modeling data and used in the analysis.\n",
        "* PMW_review.R does not include the isMerged column in its modeling data; it focuses only on review-related metrics.\n",
        "* Otherwise, both scripts process the same input data, use similar covariates, and prepare for causal inference analysis. The inclusion of isMerged in PMW_merge.R allows for analysis related to PR merge status, while PMW_review.R is focused on review characteristics."
      ],
      "metadata": {
        "id": "kNvRCCdDFmIf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5GN6LEJdGbVD"
      },
      "execution_count": 103,
      "outputs": []
    }
  ]
}