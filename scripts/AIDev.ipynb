{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Collection/Cleaning Overview\n",
        "1. **PR identification**\n",
        "   * Queried GitHub via GraphQL for PRs whose description contained the phrase **“Generated by Copilot”** or any of the marker tags:\n",
        "\n",
        "     * `copilot:summary`\n",
        "     * `copilot:walkthrough`\n",
        "     * `copilot:poem`\n",
        "     * `copilot:all`\n",
        "\n",
        "2. **Scope**\n",
        "   * Collected **18,256 PRs** from **146 early-adopter repositories** during **March 2023 – August 2023**.\n",
        "\n",
        "3. **Control set**\n",
        "   * For the same repositories, gathered **54,188 PRs** that did **not** contain any Copilot marker.\n",
        "   * These served as the **untreated (control) group** for the **RQ2 comparison**.\n",
        "\n",
        "4. **Bot filtering**\n",
        "   * Removed PRs and comments authored by bots using the **high-precision method** of **Golzadeh et al. (2022)**, which included:\n",
        "     * (i) Usernames ending with “bot”\n",
        "     * (ii) A curated list of **527 known bot accounts**\n",
        "\n",
        "5. **Revision extraction (RQ3)**\n",
        "   * From the **18,256 Copilot-generated PRs**, retrieved the full **edit history** of PR descriptions.\n",
        "   * Identified **1,437 revisions** where developers **edited the AI-suggested content**."
      ],
      "metadata": {
        "id": "j4dl0GKtyPQO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eZ03WzKRQ1bS"
      },
      "outputs": [],
      "source": [
        "import asyncio\n",
        "import matplotlib.pyplot as plt\n",
        "import nest_asyncio\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import requests\n",
        "import seaborn as sns\n",
        "import datetime\n",
        "\n",
        "from dateutil import parser\n",
        "from google.colab import userdata\n",
        "from urllib.parse import urlparse"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f9b7c674"
      },
      "source": [
        "# **First**, We need to define the URLs of the AIDev Parquet Files that we are intersted in."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "de61a39b"
      },
      "source": [
        "bot_pull_request_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/all_pull_request.parquet'\n",
        "human_pull_request_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/human_pull_request.parquet'\n",
        "pr_comments_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_comments.parquet'\n",
        "pr_commits_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_commits.parquet'\n",
        "pr_commit_details_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_commit_details.parquet'\n",
        "pr_reviews_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_reviews.parquet'\n",
        "pr_review_comments_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_review_comments.parquet'\n",
        "pr_task_type_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/pr_task_type.parquet'\n",
        "repository_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/repository.parquet'\n",
        "user_file_url = 'https://huggingface.co/datasets/hao-li/AIDev/resolve/main/all_user.parquet'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Load the Parquet file into a Pandas DataFrame from the file URL.\n",
        "\"\"\"\n",
        "def load_data(url: str):\n",
        "  import pandas as pd # Import pandas inside the function\n",
        "  try:\n",
        "    # For Parquet files:\n",
        "    df = pd.read_parquet(url)\n",
        "\n",
        "    return df\n",
        "  except Exception as e:\n",
        "      print(f\"Error loading data: {e}\")\n",
        "      print(\"Please ensure the URL is correct and the file is publicly accessible.\")\n",
        "      return None # Return None in case of an error"
      ],
      "metadata": {
        "id": "Qcu3bdoFM6UE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "818abba5"
      },
      "source": [
        "nest_asyncio.apply()\n",
        "\n",
        "GH_TOKEN = os.environ.get('GITHUB_TOKEN', userdata.get('GITHUB_TOKEN'))\n",
        "\n",
        "async def get_repo_data(repo_url: str):\n",
        "    # Make the Request\n",
        "    response = requests.get(repo_url, headers={'Authorization': f'token {GH_TOKEN}'})\n",
        "    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "    # Process the JSON response\n",
        "    return response.json()\n",
        "\n",
        "\n",
        "def get_repo_created_at(repo_url: str):\n",
        "    \"\"\"\n",
        "    Get the Repository Created At timestamp for the Repo from GitHub the API call.\n",
        "\n",
        "    Args:\n",
        "        repo_url: The GitHub API repository URL.\n",
        "\n",
        "    Returns:\n",
        "        The created_at timestamp if successful, None otherwise.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        task = asyncio.create_task(get_repo_data(repo_url))\n",
        "        event_loop = asyncio.get_running_loop()\n",
        "        if event_loop.is_running():\n",
        "          data = event_loop.run_until_complete(task)\n",
        "        else:\n",
        "          data = asyncio.run(task)\n",
        "\n",
        "        # Extract the createdAt value\n",
        "        created_at = data['created_at']\n",
        "\n",
        "        if created_at:\n",
        "            return pd.to_datetime(created_at)\n",
        "        else:\n",
        "            raise Exception(f\"Error: Could not retrieve createdAt for {repo_url}. Response data: {data}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return None\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Second**, We need to load the data from the URLs"
      ],
      "metadata": {
        "id": "CKy9xnAeb1p6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pull_request = load_data(pull_request_file_url)\n",
        "pr_comments = load_data(pr_comments_file_url)\n",
        "pr_commits = load_data(pr_commits_file_url)\n",
        "pr_commit_details = load_data(pr_commit_details_file_url)\n",
        "pr_reviews = load_data(pr_reviews_file_url)\n",
        "pr_review_comments = load_data(pr_review_comments_file_url)\n",
        "pr_task_type = load_data(pr_task_type_file_url)\n",
        "repository = load_data(repository_file_url)\n",
        "user = load_data(user_file_url)"
      ],
      "metadata": {
        "id": "YAPFfpktRJkz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Copy of Pull_Requests\n",
        "\n",
        "Remove the Open Pull Requests"
      ],
      "metadata": {
        "id": "67cBtszBeJC2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metrics = pull_request.copy()\n",
        "\n",
        "# Rename 'id' to 'pr_id' for joining\n",
        "metrics = metrics.rename(columns={'id': 'pr_id'})\n",
        "\n",
        "# Remove Open Pull Requests (closed_at is None)\n",
        "print(f\"Number of Pull Requests: {len(metrics)}\")\n",
        "metrics = metrics[metrics['closed_at'].notna()]\n",
        "print(f\"Number of Closed Pull Requests: {len(metrics)}\")\n",
        "\n",
        "# Convert Timestamps\n",
        "metrics['created_at'] = pd.to_datetime(metrics['created_at'])\n",
        "metrics['closed_at'] = pd.to_datetime(metrics['closed_at'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dz9NxumtJYVp",
        "outputId": "b17fdefb-8470-4504-c253-5e9b4feaa55c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Pull Requests: 932791\n",
            "Number of Closed Pull Requests: 859927\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "repos = repository.copy()\n",
        "\n",
        "# Rename 'id' to 'repo_id' for joining\n",
        "repos = repos.rename(columns={'id': 'repo_id'})\n",
        "\n",
        "# Remove Repositories that do not have a Pull Request\n",
        "print(f\"Number of Repositories: {len(repos)}\")\n",
        "repos = repos[repos['repo_id'].isin(metrics['repo_id'])]\n",
        "print(f\"Number of Repositories with Pull Requests: {len(repos)}\")\n",
        "repos['repo_created_at'] = repos.apply(lambda row: get_repo_created_at(row['url']), axis=1)\n",
        "repos = repos.dropna(subset=['repo_created_at'])\n",
        "print(f\"Number of Active Repositories with Pull Requests: {len(repos)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "QuyRRwfJc30t",
        "outputId": "bf645fa7-f2c9-498f-afeb-875e198ad48a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Repositories: 116211\n",
            "Number of Repositories with Pull Requests: 91526\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1144897073.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mrepos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrepos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'repo_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'repo_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of Repositories with Pull Requests: {len(repos)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrepos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'repo_created_at'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_repo_created_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mrepos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'repo_created_at'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of Repositories with Pull Requests that are Active: {len(repos)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10372\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10373\u001b[0m         )\n\u001b[0;32m> 10374\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"apply\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m  10375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m  10376\u001b[0m     def map(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    914\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1063\u001b[0;31m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1064\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1065\u001b[0m             \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_numba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1144897073.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mrepos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrepos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'repo_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'repo_id'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of Repositories with Pull Requests: {len(repos)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mrepos\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'repo_created_at'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mget_repo_created_at\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'url'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mrepos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrepos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'repo_created_at'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Number of Repositories with Pull Requests that are Active: {len(repos)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1954837550.py\u001b[0m in \u001b[0;36mget_repo_created_at\u001b[0;34m(repo_url)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mevent_loop\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_running_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_running\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m           \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevent_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_until_complete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m           \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masyncio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36mrun_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log_destroy_pending\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdone\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stopping\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/nest_asyncio.py\u001b[0m in \u001b[0;36m_run_once\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m                     \u001b[0mhandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                 \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m                     \u001b[0;31m# restore the current task\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/events.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSystemExit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step\u001b[0;34m(self, exc)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0m_enter_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__step_run_and_handle_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0m_leave_task\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_loop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/asyncio/tasks.py\u001b[0m in \u001b[0;36m__step_run_and_handle_result\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    312\u001b[0m                 \u001b[0;31m# We use the `send` method directly, because coroutines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m                 \u001b[0;31m# don't have `__iter__` and `__next__` methods.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthrow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1954837550.py\u001b[0m in \u001b[0;36mget_repo_data\u001b[0;34m(repo_url)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_repo_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_url\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# Make the Request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'Authorization'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34mf'token {GH_TOKEN}'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Raise HTTPError for bad responses (4xx or 5xx)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Process the JSON response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m     \"\"\"\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"get\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/api.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# cases, and look like a memory leak in others.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msessions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    631\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m             conn = self.get_connection_with_tls_context(\n\u001b[0m\u001b[1;32m    634\u001b[0m                 \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverify\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcert\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcert\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/requests/adapters.py\u001b[0m in \u001b[0;36mget_connection_with_tls_context\u001b[0;34m(self, request, verify, proxies, cert)\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m             \u001b[0;31m# Only scheme should be lower case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             conn = self.poolmanager.connection_from_host(\n\u001b[0m\u001b[1;32m    490\u001b[0m                 \u001b[0;34m**\u001b[0m\u001b[0mhost_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpool_kwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/poolmanager.py\u001b[0m in \u001b[0;36mconnection_from_host\u001b[0;34m(self, host, port, scheme, pool_kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m         \u001b[0mrequest_context\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"host\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection_from_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     def connection_from_context(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/urllib3/poolmanager.py\u001b[0m in \u001b[0;36mconnection_from_context\u001b[0;34m(self, request_context)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection_from_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m     def connection_from_context(\n\u001b[0m\u001b[1;32m    322\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest_context\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyping\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m     ) -> HTTPConnectionPool:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Pull Requests that do not belong to an active Repository\n",
        "print(f\"Number of Pull Requests: {len(metrics)}\")\n",
        "metrics = metrics[metrics['repo_id'].isin(repos['repo_id'])]\n",
        "print(f\"Number of Pull Requests with Repositories: {len(metrics)}\")\n",
        "\n",
        "# Count the Pull Requests by Agent\n",
        "display(metrics['agent'].value_counts())\n",
        "\n",
        "display(metrics.head(25))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9C4zS29mO0lj",
        "outputId": "83cd2370-a8c5-4c49-b4c3-0e34ccf5f926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Pull Requests: 857596\n",
            "Number of Pull Requests with Repositories: 857596\n",
            "agent\n",
            "OpenAI_Codex    758907\n",
            "Copilot          40156\n",
            "Devin            28066\n",
            "Cursor           25747\n",
            "Claude_Code       4720\n",
            "Name: count, dtype: int64\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "         pr_id  number                                              title  \\\n",
              "0   3264016139    1688  `metta code` --> `metta clip` and additional p...   \n",
              "2   3264042289    1600  Add Evals frontend implementation plan and HTM...   \n",
              "3   3264042318    1601  Add 4 new BfDs components for Evals interface ...   \n",
              "4   3264067496       3  🚀 Complete Frontend-Backend API Integration wi...   \n",
              "5   3264372403       1  Comprehensive LMSR Markets System with Weekly ...   \n",
              "6   3264398344      37  Fix Core Functionality - Search, Shows, Grids,...   \n",
              "7   3264428170     464          🚀 Complete 64-Agent System Implementation   \n",
              "8   3264481903     249  [POS-168] Sistema de Flags para Perfis de Usuá...   \n",
              "9   3264505931     145  fix: clean up linter warnings and remove dead ...   \n",
              "10  3264520290    1344  🔧 技术债务修复：消除conversion_engine.ml中的不安全类型转换 - Fix...   \n",
              "11  3264536084      93              fix: resolve GitHub workflow failures   \n",
              "12  3264552777      54  Issue #47: Complete End-to-End Integration Tes...   \n",
              "13  3264558191    1347              🧪 测试覆盖率改进：新增古雅体适用性检查器综合测试 - Fix #1342   \n",
              "14  3264574249    1349          🔧 技术债务修复：编译器源码语法一致性提升与英文注释中文化 - Fix #1348   \n",
              "16  3264598359    1351   🔧 技术债务修复：统一错误处理机制 - 消除核心模块failwith调用 - Fix #1350   \n",
              "17  3264638330    1354          🔧 技术债务修复：Token系统模块整合 - 第一阶段实现 - Fix #1353   \n",
              "18  3264677066    1606  Document codebot networking implementation str...   \n",
              "19  3264710298     149  🔧 Unified Configuration Framework for Tapio In...   \n",
              "20  3264710846    1356        🔧 技术债务修复：Token系统模块整合 - 第二阶段实现开始 - Fix #1355   \n",
              "21  3264773397      58  🧪 test(api): fix parallel test execution with ...   \n",
              "23  3264794416     147  Clean up completed task documentation and cons...   \n",
              "24  3264796443    1609  Move codebot workspace storage to ./tmp/codebo...   \n",
              "25  3264896758    1610  Enhance codebot with workspace management, con...   \n",
              "26  3264933329    2911  Fix: Wait for all partitions in load_collectio...   \n",
              "27  3264989757    1612  Move codebot workspace storage to ./tmp/codebo...   \n",
              "\n",
              "                                                 body        agent    user_id  \\\n",
              "0   Remove unused `root_key` variable to fix ruff ...  Claude_Code      37011   \n",
              "2   \\nCreate comprehensive implementation plan for...  Claude_Code    6766889   \n",
              "3   \\nPhase 1 component creation for the Evals fro...  Claude_Code    6766889   \n",
              "4   ## 🎯 Summary\\n\\nThis PR completes the **fronte...  Claude_Code   42357482   \n",
              "5   ## Summary\\n🚀 **Major platform upgrade**: Comp...  Claude_Code   62402155   \n",
              "6   ## 🚀 Critical Functionality Fixes Complete\\n\\n...  Claude_Code  215797445   \n",
              "7   # 🚀 Complete 64-Agent System Implementation\\n\\...  Claude_Code    2934394   \n",
              "8   ### **User description**\\n## Linear Ticket\\nFi...  Claude_Code   13950513   \n",
              "9   ## Summary\\n\\nThis PR addresses technical debt...  Claude_Code     692161   \n",
              "10  ## 概述\\n\\n完全修复了Issue #1343中描述的不安全类型转换问题，消除了`src...  Claude_Code  220541522   \n",
              "11  ## Summary\\n\\nThis PR resolves the persistent ...  Claude_Code   16290067   \n",
              "12  ## Summary\\n\\nThis PR implements comprehensive...  Claude_Code    1257915   \n",
              "13  ## 📋 概述\\n\\n为古雅体适用性检查器创建了全面的测试覆盖，确保古雅体风格实施状态检查功...  Claude_Code  220541522   \n",
              "14  ## 📋 概述\\n\\n本PR针对Issue #1348中识别的技术债务问题，对编译器源码进行...  Claude_Code  220541522   \n",
              "16  ## 📋 概述\\n\\n本PR针对Issue #1350中识别的错误处理技术债务问题，对4个核...  Claude_Code  220541522   \n",
              "17  ## 概述\\n\\n实现了骆言编译器Token系统的第一阶段整合，建立了统一的Token类型系...  Claude_Code  220541522   \n",
              "18  \\nAdd implementation memo outlining the curren...  Claude_Code     448694   \n",
              "19  # 🔧 Unified Configuration Framework for Tapio ...  Claude_Code  154441282   \n",
              "20  ## 概述\\n\\n完成骆言编译器Token系统的第二阶段整合工作，建立了Legacy Tok...  Claude_Code  220541522   \n",
              "21  ## 📋 Description\\n\\nFixed flaky integration te...  Claude_Code   32826608   \n",
              "23  ## Summary\\n\\nSystematic cleanup of outdated d...  Claude_Code    5819722   \n",
              "24  \\nRelocate container workspace management from...  Claude_Code     448694   \n",
              "25  \\nAdd advanced workspace management features, ...  Claude_Code     448694   \n",
              "26  ## Summary\\n\\nFixes an issue where `load_colle...  Claude_Code  108661493   \n",
              "27  \\nRelocate container workspace management from...  Claude_Code     448694   \n",
              "\n",
              "                  user   state                created_at  \\\n",
              "0        jacklionheart  closed 2025-07-25 18:15:36+00:00   \n",
              "2            justicart  closed 2025-07-25 18:26:15+00:00   \n",
              "3            justicart  closed 2025-07-25 18:26:16+00:00   \n",
              "4            twitchyvr  closed 2025-07-25 18:39:14+00:00   \n",
              "5           derspotter  closed 2025-07-25 20:59:39+00:00   \n",
              "6   terragon-labs[bot]  closed 2025-07-25 21:12:12+00:00   \n",
              "7               ruvnet  closed 2025-07-25 21:26:37+00:00   \n",
              "8           angelod1as  closed 2025-07-25 21:56:42+00:00   \n",
              "9              lbds137  closed 2025-07-25 22:08:19+00:00   \n",
              "10    claudeai-v1[bot]  closed 2025-07-25 22:16:16+00:00   \n",
              "11        learnednomad  closed 2025-07-25 22:27:08+00:00   \n",
              "12          datablogin  closed 2025-07-25 22:39:02+00:00   \n",
              "13    claudeai-v1[bot]  closed 2025-07-25 22:43:03+00:00   \n",
              "14    claudeai-v1[bot]  closed 2025-07-25 22:56:32+00:00   \n",
              "16    claudeai-v1[bot]  closed 2025-07-25 23:10:06+00:00   \n",
              "17    claudeai-v1[bot]  closed 2025-07-25 23:33:32+00:00   \n",
              "18            randallb  closed 2025-07-25 23:52:25+00:00   \n",
              "19           yairfalse  closed 2025-07-26 00:11:13+00:00   \n",
              "20    claudeai-v1[bot]  closed 2025-07-26 00:11:34+00:00   \n",
              "21           Kaniikura  closed 2025-07-26 00:50:12+00:00   \n",
              "23    timothyfroehlich  closed 2025-07-26 01:06:16+00:00   \n",
              "24            randallb  closed 2025-07-26 01:07:32+00:00   \n",
              "25            randallb  closed 2025-07-26 02:26:43+00:00   \n",
              "26          weiliu1031  closed 2025-07-26 02:59:01+00:00   \n",
              "27            randallb  closed 2025-07-26 03:31:11+00:00   \n",
              "\n",
              "                   closed_at             merged_at       repo_id  \\\n",
              "0  2025-07-25 19:17:23+00:00  2025-07-25T19:17:23Z  8.439884e+08   \n",
              "2  2025-07-25 23:19:14+00:00                  None  9.267118e+08   \n",
              "3  2025-07-25 23:19:11+00:00                  None  9.267118e+08   \n",
              "4  2025-07-25 18:48:47+00:00  2025-07-25T18:48:47Z  1.025871e+09   \n",
              "5  2025-07-28 12:01:05+00:00  2025-07-28T12:01:05Z  9.249577e+08   \n",
              "6  2025-07-26 21:29:24+00:00  2025-07-26T21:29:24Z  1.007375e+09   \n",
              "7  2025-07-25 21:29:18+00:00                  None  9.950296e+08   \n",
              "8  2025-07-25 22:25:37+00:00  2025-07-25T22:25:37Z  9.744943e+08   \n",
              "9  2025-07-25 23:58:55+00:00  2025-07-25T23:58:55Z  9.854695e+08   \n",
              "10 2025-07-25 22:21:18+00:00  2025-07-25T22:21:18Z  1.017722e+09   \n",
              "11 2025-07-25 22:27:20+00:00  2025-07-25T22:27:20Z  1.015297e+09   \n",
              "12 2025-07-25 23:29:29+00:00  2025-07-25T23:29:29Z  1.022864e+09   \n",
              "13 2025-07-25 22:47:15+00:00  2025-07-25T22:47:15Z  1.017722e+09   \n",
              "14 2025-07-25 23:00:19+00:00  2025-07-25T23:00:19Z  1.017722e+09   \n",
              "16 2025-07-25 23:19:49+00:00  2025-07-25T23:19:49Z  1.017722e+09   \n",
              "17 2025-07-25 23:58:12+00:00  2025-07-25T23:58:12Z  1.017722e+09   \n",
              "18 2025-07-26 00:28:14+00:00  2025-07-26T00:28:14Z  9.267118e+08   \n",
              "19 2025-07-26 00:12:10+00:00  2025-07-26T00:12:10Z  1.015295e+09   \n",
              "20 2025-07-26 04:03:31+00:00  2025-07-26T04:03:31Z  1.017722e+09   \n",
              "21 2025-07-26 02:46:58+00:00  2025-07-26T02:46:58Z  9.968184e+08   \n",
              "23 2025-07-26 01:08:14+00:00  2025-07-26T01:08:14Z  1.008724e+09   \n",
              "24 2025-07-26 21:47:32+00:00                  None  9.267118e+08   \n",
              "25 2025-07-26 21:51:51+00:00  2025-07-26T21:51:51Z  9.267118e+08   \n",
              "26 2025-07-29 07:01:20+00:00                  None  1.917515e+08   \n",
              "27 2025-07-26 21:44:12+00:00                  None  9.267118e+08   \n",
              "\n",
              "                                             repo_url  \\\n",
              "0         https://api.github.com/repos/Metta-AI/metta   \n",
              "2   https://api.github.com/repos/bolt-foundry/bolt...   \n",
              "3   https://api.github.com/repos/bolt-foundry/bolt...   \n",
              "4    https://api.github.com/repos/twitchyvr/Spaghetti   \n",
              "5   https://api.github.com/repos/derspotter/intell...   \n",
              "6     https://api.github.com/repos/swbam/mysetlist-s4   \n",
              "7     https://api.github.com/repos/ruvnet/claude-flow   \n",
              "8     https://api.github.com/repos/angelod1as/positiv   \n",
              "9         https://api.github.com/repos/lbds137/tzurot   \n",
              "10  https://api.github.com/repos/UltimatePea/chine...   \n",
              "11  https://api.github.com/repos/learnednomad/sabr...   \n",
              "12  https://api.github.com/repos/datablogin/analyt...   \n",
              "13  https://api.github.com/repos/UltimatePea/chine...   \n",
              "14  https://api.github.com/repos/UltimatePea/chine...   \n",
              "16  https://api.github.com/repos/UltimatePea/chine...   \n",
              "17  https://api.github.com/repos/UltimatePea/chine...   \n",
              "18  https://api.github.com/repos/bolt-foundry/bolt...   \n",
              "19       https://api.github.com/repos/yairfalse/tapio   \n",
              "20  https://api.github.com/repos/UltimatePea/chine...   \n",
              "21    https://api.github.com/repos/Kaniikura/certquiz   \n",
              "23  https://api.github.com/repos/timothyfroehlich/...   \n",
              "24  https://api.github.com/repos/bolt-foundry/bolt...   \n",
              "25  https://api.github.com/repos/bolt-foundry/bolt...   \n",
              "26    https://api.github.com/repos/milvus-io/pymilvus   \n",
              "27  https://api.github.com/repos/bolt-foundry/bolt...   \n",
              "\n",
              "                                             html_url  \n",
              "0         https://github.com/Metta-AI/metta/pull/1688  \n",
              "2   https://github.com/bolt-foundry/bolt-foundry/p...  \n",
              "3   https://github.com/bolt-foundry/bolt-foundry/p...  \n",
              "4       https://github.com/twitchyvr/Spaghetti/pull/3  \n",
              "5   https://github.com/derspotter/intellacc.com/pu...  \n",
              "6       https://github.com/swbam/mysetlist-s4/pull/37  \n",
              "7      https://github.com/ruvnet/claude-flow/pull/464  \n",
              "8      https://github.com/angelod1as/positiv/pull/249  \n",
              "9          https://github.com/lbds137/tzurot/pull/145  \n",
              "10  https://github.com/UltimatePea/chinese-ocaml/p...  \n",
              "11  https://github.com/learnednomad/sabron-trip-sy...  \n",
              "12  https://github.com/datablogin/analytics-backen...  \n",
              "13  https://github.com/UltimatePea/chinese-ocaml/p...  \n",
              "14  https://github.com/UltimatePea/chinese-ocaml/p...  \n",
              "16  https://github.com/UltimatePea/chinese-ocaml/p...  \n",
              "17  https://github.com/UltimatePea/chinese-ocaml/p...  \n",
              "18  https://github.com/bolt-foundry/bolt-foundry/p...  \n",
              "19        https://github.com/yairfalse/tapio/pull/149  \n",
              "20  https://github.com/UltimatePea/chinese-ocaml/p...  \n",
              "21      https://github.com/Kaniikura/certquiz/pull/58  \n",
              "23  https://github.com/timothyfroehlich/PinPoint/p...  \n",
              "24  https://github.com/bolt-foundry/bolt-foundry/p...  \n",
              "25  https://github.com/bolt-foundry/bolt-foundry/p...  \n",
              "26    https://github.com/milvus-io/pymilvus/pull/2911  \n",
              "27  https://github.com/bolt-foundry/bolt-foundry/p...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-47aad5ba-d1c3-453f-8e53-fc5cb47540e4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pr_id</th>\n",
              "      <th>number</th>\n",
              "      <th>title</th>\n",
              "      <th>body</th>\n",
              "      <th>agent</th>\n",
              "      <th>user_id</th>\n",
              "      <th>user</th>\n",
              "      <th>state</th>\n",
              "      <th>created_at</th>\n",
              "      <th>closed_at</th>\n",
              "      <th>merged_at</th>\n",
              "      <th>repo_id</th>\n",
              "      <th>repo_url</th>\n",
              "      <th>html_url</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3264016139</td>\n",
              "      <td>1688</td>\n",
              "      <td>`metta code` --&gt; `metta clip` and additional p...</td>\n",
              "      <td>Remove unused `root_key` variable to fix ruff ...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>37011</td>\n",
              "      <td>jacklionheart</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 18:15:36+00:00</td>\n",
              "      <td>2025-07-25 19:17:23+00:00</td>\n",
              "      <td>2025-07-25T19:17:23Z</td>\n",
              "      <td>8.439884e+08</td>\n",
              "      <td>https://api.github.com/repos/Metta-AI/metta</td>\n",
              "      <td>https://github.com/Metta-AI/metta/pull/1688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3264042289</td>\n",
              "      <td>1600</td>\n",
              "      <td>Add Evals frontend implementation plan and HTM...</td>\n",
              "      <td>\\nCreate comprehensive implementation plan for...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>6766889</td>\n",
              "      <td>justicart</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 18:26:15+00:00</td>\n",
              "      <td>2025-07-25 23:19:14+00:00</td>\n",
              "      <td>None</td>\n",
              "      <td>9.267118e+08</td>\n",
              "      <td>https://api.github.com/repos/bolt-foundry/bolt...</td>\n",
              "      <td>https://github.com/bolt-foundry/bolt-foundry/p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3264042318</td>\n",
              "      <td>1601</td>\n",
              "      <td>Add 4 new BfDs components for Evals interface ...</td>\n",
              "      <td>\\nPhase 1 component creation for the Evals fro...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>6766889</td>\n",
              "      <td>justicart</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 18:26:16+00:00</td>\n",
              "      <td>2025-07-25 23:19:11+00:00</td>\n",
              "      <td>None</td>\n",
              "      <td>9.267118e+08</td>\n",
              "      <td>https://api.github.com/repos/bolt-foundry/bolt...</td>\n",
              "      <td>https://github.com/bolt-foundry/bolt-foundry/p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3264067496</td>\n",
              "      <td>3</td>\n",
              "      <td>🚀 Complete Frontend-Backend API Integration wi...</td>\n",
              "      <td>## 🎯 Summary\\n\\nThis PR completes the **fronte...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>42357482</td>\n",
              "      <td>twitchyvr</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 18:39:14+00:00</td>\n",
              "      <td>2025-07-25 18:48:47+00:00</td>\n",
              "      <td>2025-07-25T18:48:47Z</td>\n",
              "      <td>1.025871e+09</td>\n",
              "      <td>https://api.github.com/repos/twitchyvr/Spaghetti</td>\n",
              "      <td>https://github.com/twitchyvr/Spaghetti/pull/3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>3264372403</td>\n",
              "      <td>1</td>\n",
              "      <td>Comprehensive LMSR Markets System with Weekly ...</td>\n",
              "      <td>## Summary\\n🚀 **Major platform upgrade**: Comp...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>62402155</td>\n",
              "      <td>derspotter</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 20:59:39+00:00</td>\n",
              "      <td>2025-07-28 12:01:05+00:00</td>\n",
              "      <td>2025-07-28T12:01:05Z</td>\n",
              "      <td>9.249577e+08</td>\n",
              "      <td>https://api.github.com/repos/derspotter/intell...</td>\n",
              "      <td>https://github.com/derspotter/intellacc.com/pu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3264398344</td>\n",
              "      <td>37</td>\n",
              "      <td>Fix Core Functionality - Search, Shows, Grids,...</td>\n",
              "      <td>## 🚀 Critical Functionality Fixes Complete\\n\\n...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>215797445</td>\n",
              "      <td>terragon-labs[bot]</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 21:12:12+00:00</td>\n",
              "      <td>2025-07-26 21:29:24+00:00</td>\n",
              "      <td>2025-07-26T21:29:24Z</td>\n",
              "      <td>1.007375e+09</td>\n",
              "      <td>https://api.github.com/repos/swbam/mysetlist-s4</td>\n",
              "      <td>https://github.com/swbam/mysetlist-s4/pull/37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>3264428170</td>\n",
              "      <td>464</td>\n",
              "      <td>🚀 Complete 64-Agent System Implementation</td>\n",
              "      <td># 🚀 Complete 64-Agent System Implementation\\n\\...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>2934394</td>\n",
              "      <td>ruvnet</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 21:26:37+00:00</td>\n",
              "      <td>2025-07-25 21:29:18+00:00</td>\n",
              "      <td>None</td>\n",
              "      <td>9.950296e+08</td>\n",
              "      <td>https://api.github.com/repos/ruvnet/claude-flow</td>\n",
              "      <td>https://github.com/ruvnet/claude-flow/pull/464</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>3264481903</td>\n",
              "      <td>249</td>\n",
              "      <td>[POS-168] Sistema de Flags para Perfis de Usuá...</td>\n",
              "      <td>### **User description**\\n## Linear Ticket\\nFi...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>13950513</td>\n",
              "      <td>angelod1as</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 21:56:42+00:00</td>\n",
              "      <td>2025-07-25 22:25:37+00:00</td>\n",
              "      <td>2025-07-25T22:25:37Z</td>\n",
              "      <td>9.744943e+08</td>\n",
              "      <td>https://api.github.com/repos/angelod1as/positiv</td>\n",
              "      <td>https://github.com/angelod1as/positiv/pull/249</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>3264505931</td>\n",
              "      <td>145</td>\n",
              "      <td>fix: clean up linter warnings and remove dead ...</td>\n",
              "      <td>## Summary\\n\\nThis PR addresses technical debt...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>692161</td>\n",
              "      <td>lbds137</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 22:08:19+00:00</td>\n",
              "      <td>2025-07-25 23:58:55+00:00</td>\n",
              "      <td>2025-07-25T23:58:55Z</td>\n",
              "      <td>9.854695e+08</td>\n",
              "      <td>https://api.github.com/repos/lbds137/tzurot</td>\n",
              "      <td>https://github.com/lbds137/tzurot/pull/145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>3264520290</td>\n",
              "      <td>1344</td>\n",
              "      <td>🔧 技术债务修复：消除conversion_engine.ml中的不安全类型转换 - Fix...</td>\n",
              "      <td>## 概述\\n\\n完全修复了Issue #1343中描述的不安全类型转换问题，消除了`src...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>220541522</td>\n",
              "      <td>claudeai-v1[bot]</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 22:16:16+00:00</td>\n",
              "      <td>2025-07-25 22:21:18+00:00</td>\n",
              "      <td>2025-07-25T22:21:18Z</td>\n",
              "      <td>1.017722e+09</td>\n",
              "      <td>https://api.github.com/repos/UltimatePea/chine...</td>\n",
              "      <td>https://github.com/UltimatePea/chinese-ocaml/p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>3264536084</td>\n",
              "      <td>93</td>\n",
              "      <td>fix: resolve GitHub workflow failures</td>\n",
              "      <td>## Summary\\n\\nThis PR resolves the persistent ...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>16290067</td>\n",
              "      <td>learnednomad</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 22:27:08+00:00</td>\n",
              "      <td>2025-07-25 22:27:20+00:00</td>\n",
              "      <td>2025-07-25T22:27:20Z</td>\n",
              "      <td>1.015297e+09</td>\n",
              "      <td>https://api.github.com/repos/learnednomad/sabr...</td>\n",
              "      <td>https://github.com/learnednomad/sabron-trip-sy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>3264552777</td>\n",
              "      <td>54</td>\n",
              "      <td>Issue #47: Complete End-to-End Integration Tes...</td>\n",
              "      <td>## Summary\\n\\nThis PR implements comprehensive...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>1257915</td>\n",
              "      <td>datablogin</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 22:39:02+00:00</td>\n",
              "      <td>2025-07-25 23:29:29+00:00</td>\n",
              "      <td>2025-07-25T23:29:29Z</td>\n",
              "      <td>1.022864e+09</td>\n",
              "      <td>https://api.github.com/repos/datablogin/analyt...</td>\n",
              "      <td>https://github.com/datablogin/analytics-backen...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>3264558191</td>\n",
              "      <td>1347</td>\n",
              "      <td>🧪 测试覆盖率改进：新增古雅体适用性检查器综合测试 - Fix #1342</td>\n",
              "      <td>## 📋 概述\\n\\n为古雅体适用性检查器创建了全面的测试覆盖，确保古雅体风格实施状态检查功...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>220541522</td>\n",
              "      <td>claudeai-v1[bot]</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 22:43:03+00:00</td>\n",
              "      <td>2025-07-25 22:47:15+00:00</td>\n",
              "      <td>2025-07-25T22:47:15Z</td>\n",
              "      <td>1.017722e+09</td>\n",
              "      <td>https://api.github.com/repos/UltimatePea/chine...</td>\n",
              "      <td>https://github.com/UltimatePea/chinese-ocaml/p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>3264574249</td>\n",
              "      <td>1349</td>\n",
              "      <td>🔧 技术债务修复：编译器源码语法一致性提升与英文注释中文化 - Fix #1348</td>\n",
              "      <td>## 📋 概述\\n\\n本PR针对Issue #1348中识别的技术债务问题，对编译器源码进行...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>220541522</td>\n",
              "      <td>claudeai-v1[bot]</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 22:56:32+00:00</td>\n",
              "      <td>2025-07-25 23:00:19+00:00</td>\n",
              "      <td>2025-07-25T23:00:19Z</td>\n",
              "      <td>1.017722e+09</td>\n",
              "      <td>https://api.github.com/repos/UltimatePea/chine...</td>\n",
              "      <td>https://github.com/UltimatePea/chinese-ocaml/p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>3264598359</td>\n",
              "      <td>1351</td>\n",
              "      <td>🔧 技术债务修复：统一错误处理机制 - 消除核心模块failwith调用 - Fix #1350</td>\n",
              "      <td>## 📋 概述\\n\\n本PR针对Issue #1350中识别的错误处理技术债务问题，对4个核...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>220541522</td>\n",
              "      <td>claudeai-v1[bot]</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 23:10:06+00:00</td>\n",
              "      <td>2025-07-25 23:19:49+00:00</td>\n",
              "      <td>2025-07-25T23:19:49Z</td>\n",
              "      <td>1.017722e+09</td>\n",
              "      <td>https://api.github.com/repos/UltimatePea/chine...</td>\n",
              "      <td>https://github.com/UltimatePea/chinese-ocaml/p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>3264638330</td>\n",
              "      <td>1354</td>\n",
              "      <td>🔧 技术债务修复：Token系统模块整合 - 第一阶段实现 - Fix #1353</td>\n",
              "      <td>## 概述\\n\\n实现了骆言编译器Token系统的第一阶段整合，建立了统一的Token类型系...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>220541522</td>\n",
              "      <td>claudeai-v1[bot]</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 23:33:32+00:00</td>\n",
              "      <td>2025-07-25 23:58:12+00:00</td>\n",
              "      <td>2025-07-25T23:58:12Z</td>\n",
              "      <td>1.017722e+09</td>\n",
              "      <td>https://api.github.com/repos/UltimatePea/chine...</td>\n",
              "      <td>https://github.com/UltimatePea/chinese-ocaml/p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>3264677066</td>\n",
              "      <td>1606</td>\n",
              "      <td>Document codebot networking implementation str...</td>\n",
              "      <td>\\nAdd implementation memo outlining the curren...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>448694</td>\n",
              "      <td>randallb</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-25 23:52:25+00:00</td>\n",
              "      <td>2025-07-26 00:28:14+00:00</td>\n",
              "      <td>2025-07-26T00:28:14Z</td>\n",
              "      <td>9.267118e+08</td>\n",
              "      <td>https://api.github.com/repos/bolt-foundry/bolt...</td>\n",
              "      <td>https://github.com/bolt-foundry/bolt-foundry/p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>3264710298</td>\n",
              "      <td>149</td>\n",
              "      <td>🔧 Unified Configuration Framework for Tapio In...</td>\n",
              "      <td># 🔧 Unified Configuration Framework for Tapio ...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>154441282</td>\n",
              "      <td>yairfalse</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-26 00:11:13+00:00</td>\n",
              "      <td>2025-07-26 00:12:10+00:00</td>\n",
              "      <td>2025-07-26T00:12:10Z</td>\n",
              "      <td>1.015295e+09</td>\n",
              "      <td>https://api.github.com/repos/yairfalse/tapio</td>\n",
              "      <td>https://github.com/yairfalse/tapio/pull/149</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>3264710846</td>\n",
              "      <td>1356</td>\n",
              "      <td>🔧 技术债务修复：Token系统模块整合 - 第二阶段实现开始 - Fix #1355</td>\n",
              "      <td>## 概述\\n\\n完成骆言编译器Token系统的第二阶段整合工作，建立了Legacy Tok...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>220541522</td>\n",
              "      <td>claudeai-v1[bot]</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-26 00:11:34+00:00</td>\n",
              "      <td>2025-07-26 04:03:31+00:00</td>\n",
              "      <td>2025-07-26T04:03:31Z</td>\n",
              "      <td>1.017722e+09</td>\n",
              "      <td>https://api.github.com/repos/UltimatePea/chine...</td>\n",
              "      <td>https://github.com/UltimatePea/chinese-ocaml/p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>3264773397</td>\n",
              "      <td>58</td>\n",
              "      <td>🧪 test(api): fix parallel test execution with ...</td>\n",
              "      <td>## 📋 Description\\n\\nFixed flaky integration te...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>32826608</td>\n",
              "      <td>Kaniikura</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-26 00:50:12+00:00</td>\n",
              "      <td>2025-07-26 02:46:58+00:00</td>\n",
              "      <td>2025-07-26T02:46:58Z</td>\n",
              "      <td>9.968184e+08</td>\n",
              "      <td>https://api.github.com/repos/Kaniikura/certquiz</td>\n",
              "      <td>https://github.com/Kaniikura/certquiz/pull/58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>3264794416</td>\n",
              "      <td>147</td>\n",
              "      <td>Clean up completed task documentation and cons...</td>\n",
              "      <td>## Summary\\n\\nSystematic cleanup of outdated d...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>5819722</td>\n",
              "      <td>timothyfroehlich</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-26 01:06:16+00:00</td>\n",
              "      <td>2025-07-26 01:08:14+00:00</td>\n",
              "      <td>2025-07-26T01:08:14Z</td>\n",
              "      <td>1.008724e+09</td>\n",
              "      <td>https://api.github.com/repos/timothyfroehlich/...</td>\n",
              "      <td>https://github.com/timothyfroehlich/PinPoint/p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>3264796443</td>\n",
              "      <td>1609</td>\n",
              "      <td>Move codebot workspace storage to ./tmp/codebo...</td>\n",
              "      <td>\\nRelocate container workspace management from...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>448694</td>\n",
              "      <td>randallb</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-26 01:07:32+00:00</td>\n",
              "      <td>2025-07-26 21:47:32+00:00</td>\n",
              "      <td>None</td>\n",
              "      <td>9.267118e+08</td>\n",
              "      <td>https://api.github.com/repos/bolt-foundry/bolt...</td>\n",
              "      <td>https://github.com/bolt-foundry/bolt-foundry/p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>3264896758</td>\n",
              "      <td>1610</td>\n",
              "      <td>Enhance codebot with workspace management, con...</td>\n",
              "      <td>\\nAdd advanced workspace management features, ...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>448694</td>\n",
              "      <td>randallb</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-26 02:26:43+00:00</td>\n",
              "      <td>2025-07-26 21:51:51+00:00</td>\n",
              "      <td>2025-07-26T21:51:51Z</td>\n",
              "      <td>9.267118e+08</td>\n",
              "      <td>https://api.github.com/repos/bolt-foundry/bolt...</td>\n",
              "      <td>https://github.com/bolt-foundry/bolt-foundry/p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>3264933329</td>\n",
              "      <td>2911</td>\n",
              "      <td>Fix: Wait for all partitions in load_collectio...</td>\n",
              "      <td>## Summary\\n\\nFixes an issue where `load_colle...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>108661493</td>\n",
              "      <td>weiliu1031</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-26 02:59:01+00:00</td>\n",
              "      <td>2025-07-29 07:01:20+00:00</td>\n",
              "      <td>None</td>\n",
              "      <td>1.917515e+08</td>\n",
              "      <td>https://api.github.com/repos/milvus-io/pymilvus</td>\n",
              "      <td>https://github.com/milvus-io/pymilvus/pull/2911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>3264989757</td>\n",
              "      <td>1612</td>\n",
              "      <td>Move codebot workspace storage to ./tmp/codebo...</td>\n",
              "      <td>\\nRelocate container workspace management from...</td>\n",
              "      <td>Claude_Code</td>\n",
              "      <td>448694</td>\n",
              "      <td>randallb</td>\n",
              "      <td>closed</td>\n",
              "      <td>2025-07-26 03:31:11+00:00</td>\n",
              "      <td>2025-07-26 21:44:12+00:00</td>\n",
              "      <td>None</td>\n",
              "      <td>9.267118e+08</td>\n",
              "      <td>https://api.github.com/repos/bolt-foundry/bolt...</td>\n",
              "      <td>https://github.com/bolt-foundry/bolt-foundry/p...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-47aad5ba-d1c3-453f-8e53-fc5cb47540e4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-47aad5ba-d1c3-453f-8e53-fc5cb47540e4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-47aad5ba-d1c3-453f-8e53-fc5cb47540e4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-41e88d70-9154-44bf-9a1f-ab75214f1523\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-41e88d70-9154-44bf-9a1f-ab75214f1523')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-41e88d70-9154-44bf-9a1f-ab75214f1523 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(metrics\",\n  \"rows\": 25,\n  \"fields\": [\n    {\n      \"column\": \"pr_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 275311,\n        \"min\": 3264016139,\n        \"max\": 3264989757,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          3264505931,\n          3264677066,\n          3264016139\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"number\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 805,\n        \"min\": 1,\n        \"max\": 2911,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          145,\n          1606,\n          1688\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"title\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"fix: clean up linter warnings and remove dead code\",\n          \"Document codebot networking implementation strategy\",\n          \"`metta code` --> `metta clip` and additional polish\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"body\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"## Summary\\n\\nThis PR addresses technical debt by cleaning up linter warnings and removing dead code that was identified as unused.\\n\\n### Changes Made\\n\\n1. **Removed contentSanitizer module** (~367 lines removed)\\n   - AI service doesn't return control characters, making sanitization unnecessary\\n   - Removed from aiService.js and aiMessageFormatter.js\\n   - Deleted contentSanitizer.js and all related tests\\n\\n2. **Fixed unused variable warnings** (reduced from 69 to 30)\\n   - Fixed ESLint configuration to properly handle underscore-prefixed caught errors\\n   - Prefixed unused parameters in interface/abstract methods with underscores\\n   - Removed completely unused imports and variables\\n   - Removed deprecated initialize() functions from profileInfoFetcher and webhookUserTracker\\n\\n3. **Removed DDD system indicators**\\n   - Removed feature flag checks and \\\"\\ud83c\\udd95 Created with new DDD system\\\" messages\\n   - Cleaned up from AddCommand, AliasCommand, RemoveCommand, ListCommand\\n\\n4. **Other improvements**\\n   - Removed unused parameters from concrete implementations\\n   - Fixed parameter names in event handlers\\n   - Cleaned up unused imports (WebhookClient, urlValidator, etc.)\\n\\n### Testing\\n\\n- \\u2705 All tests pass (4138 tests)\\n- \\u2705 Test coverage maintained (>90% on modified files)\\n- \\u2705 Verified all removed code was truly unused\\n- \\u2705 No breaking changes - only dead code removal\\n\\n### Impact\\n\\n- **51 files changed**\\n- **89 insertions, 673 deletions** (net -584 lines)\\n- Cleaner, more maintainable codebase\\n- Reduced linter warnings significantly\\n\\n\\ud83e\\udd16 Generated with [Claude Code](https://claude.ai/code)\\n\\nCo-Authored-By: Claude <noreply@anthropic.com>\",\n          \"\\nAdd implementation memo outlining the current state and next steps for codebot networking infrastructure. The memo documents proven working components (reverse proxy, DNS service, container discovery) and recommends simplifying the approach by shipping proxy-only first rather than fighting test infrastructure complexity.\\n\\nChanges:\\n- Add codebot-networking-implementation.md with technical status and recommendations\\n- Document three implementation options: proxy-only, hosts file management, and browser extension\\n- Recommend proxy-only approach for initial ship to prioritize working functionality over perfect DNS resolution\\n- Outline clear phase 1 (ship proxy) and phase 2 (optional DNS) implementation plan\\n\\nTest plan:\\n1. Review memo content for technical accuracy\\n2. Verify recommendations align with \\\"simple is almost always better than complex\\\" principle\\n3. Confirm next steps provide clear path forward for codebot integration\\n\\n\\ud83e\\udd16 Generated with [Claude Code](https://claude.ai/code)\\n\\nCo-Authored-By: Claude <noreply@anthropic.com>\\n\",\n          \"Remove unused `root_key` variable to fix ruff linting error F841\\n\\n\\ud83e\\udd16 Generated with [Claude Code](https://claude.ai/code)\\n\\nCo-Authored-By: Claude <noreply@anthropic.com>\\n\\n[Asana Task](https://app.asana.com/1/1209016784099267/project/1210348820405981/task/1210892261488990)\\n\\n[Asana Task](https://app.asana.com/1/1209016784099267/project/1210348820405981/task/1210892111424511)\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"agent\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"Claude_Code\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 96188628,\n        \"min\": 37011,\n        \"max\": 220541522,\n        \"num_unique_values\": 16,\n        \"samples\": [\n          37011\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"user\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 16,\n        \"samples\": [\n          \"jacklionheart\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"state\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"closed\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"created_at\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-07-25 18:15:36+00:00\",\n        \"max\": \"2025-07-26 03:31:11+00:00\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"2025-07-25 22:08:19+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"closed_at\",\n      \"properties\": {\n        \"dtype\": \"date\",\n        \"min\": \"2025-07-25 18:48:47+00:00\",\n        \"max\": \"2025-07-29 07:01:20+00:00\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"2025-07-25 23:58:55+00:00\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"merged_at\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 19,\n        \"samples\": [\n          \"2025-07-25T19:17:23Z\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"repo_id\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 164539939.77922863,\n        \"min\": 191751505.0,\n        \"max\": 1025871154.0,\n        \"num_unique_values\": 15,\n        \"samples\": [\n          1015297093.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"repo_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 15,\n        \"samples\": [\n          \"https://api.github.com/repos/learnednomad/sabron-trip-sync\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"html_url\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 25,\n        \"samples\": [\n          \"https://github.com/lbds137/tzurot/pull/145\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Third**, Gather the covariant variables\n"
      ],
      "metadata": {
        "id": "a30SFFhZXgy4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PR Variables"
      ],
      "metadata": {
        "id": "xANcFKyCb9Fm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. **additions:** The # of added LOC by a PR\n",
        "2. **deletions:** The # of deleted LOC by a PR\n",
        "3. **prSize:** The total number of added and deleted LOC by a PR (additions + deletions)\n"
      ],
      "metadata": {
        "id": "zP1sNtj3eIRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['additions', 'deletions', 'prSize'], errors='ignore')\n",
        "\n",
        "# Get the sums of the columns we are interested in\n",
        "pr_commit_LOC = (pr_commit_details.groupby(['pr_id'])\n",
        "                                  .sum(['additions', 'deletions', 'changes'])\n",
        "                                  .reset_index())\n",
        "\n",
        "# Rename the sum columns to what we want\n",
        "pr_commit_LOC = (pr_commit_LOC.rename(columns={'changes': 'prSize'}))\n",
        "\n",
        "# Drop the extraneous columns\n",
        "pr_commit_LOC = pr_commit_LOC.drop(columns=['commit_stats_total',\n",
        "                                            'commit_stats_additions',\n",
        "                                            'commit_stats_deletions'])\n",
        "\n",
        "# Merge the Dataframes with a left join\n",
        "metrics = pd.merge(metrics, pr_commit_LOC, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage collect the temporary Dataframe\n",
        "pr_commit_LOC = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['additions'] = metrics['additions'].fillna(0).astype(int)\n",
        "metrics['deletions'] = metrics['deletions'].fillna(0).astype(int)\n",
        "metrics['prSize'] = metrics['prSize'].fillna(0).astype(int)\n"
      ],
      "metadata": {
        "id": "nj9typbGIcI2",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. **purpose:** The purpose of a PR, i.e., bug, document, and feature. Simple keyword search in the title/body ('fix', 'bug', 'doc', …).\n"
      ],
      "metadata": {
        "id": "_9ULLRD1eVyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['purpose'], errors='ignore')\n",
        "\n",
        "# Make a copy of the PR Task Type Dataframe and Drop unneeded columns\n",
        "pr_task = (pr_task_type.copy()\n",
        "                       .rename(columns={'id': 'pr_id'})\n",
        "                       .drop(columns=['agent', 'title', 'reason', 'confidence'], errors='ignore'))\n",
        "\n",
        "# Filter the PR Tasks to bug, feature or document\n",
        "pr_task = pr_task[pr_task['type'].isin(['fix', 'feat', 'doc'])]\n",
        "\n",
        "# Group by ID and get the First Record\n",
        "pr_task = pr_task.groupby(['pr_id']).first()\n",
        "\n",
        "# Rename the column to what we want to keep\n",
        "pr_task = pr_task.rename(columns={'type': 'purpose'})\n",
        "\n",
        "# Merge the Dataframes with a left join\n",
        "metrics = pd.merge(metrics, pr_task, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframe\n",
        "pr_task = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['purpose'] = metrics['purpose'].fillna('other')\n",
        "\n",
        "#Check that the purpose = either of the three options; Bug, Feature, Document\n",
        "metrics = metrics[metrics['purpose'].isin(['fix', 'feat', 'doc'])]"
      ],
      "metadata": {
        "id": "Hc2sYaVwFPdL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. **changedFiles:** The # of files changed by a PR\n"
      ],
      "metadata": {
        "id": "jKdoh7knfFD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['changedFiles'], errors='ignore')\n",
        "\n",
        "# Count the number of Files changed and change the column name to what we want\n",
        "pr_files_changed = (pr_commit_details.groupby(['pr_id', 'filename'])\n",
        "                                     .size()\n",
        "                                     .groupby(['pr_id'])\n",
        "                                     .size()\n",
        "                                     .reset_index(name='changedFiles'))\n",
        "\n",
        "# Merge the Dataframes with a left join\n",
        "metrics = pd.merge(metrics, pr_files_changed, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframe\n",
        "pr_files_changed = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['changedFiles'] = metrics['changedFiles'].fillna(0).astype(int)\n"
      ],
      "metadata": {
        "id": "YwnUjWn9FPY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. **commitsTotalCount:** The # of commits involved in a PR\n"
      ],
      "metadata": {
        "id": "xxZIoTx8fiCT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['commitsTotalCount'], errors='ignore')\n",
        "\n",
        "# Count the number of Commits for the Pull Request, name the column what we want.\n",
        "pr_commits_count = pr_commits.groupby(['pr_id']).size().reset_index(name='commitsTotalCount')\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, pr_commits_count, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframe\n",
        "pr_commits_count = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['commitsTotalCount'] = metrics['commitsTotalCount'].fillna(0).astype(int)\n"
      ],
      "metadata": {
        "id": "vOyzUxnHFPUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. **Description length:** The length of a PR description\n"
      ],
      "metadata": {
        "id": "Ed6fS14afxfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['bodyLength'], errors='ignore')\n",
        "\n",
        "# Get the Length of the Body of the Pull Request\n",
        "metrics['bodyLength'] = metrics['body'].str.len()"
      ],
      "metadata": {
        "id": "OZYyz-mVFPPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. **prExperience:** The # of prior PRs that were submitted by the PR author (author’s prior PR count). Query the author’s PR history in the same repo and count PRs created before the current one.\n"
      ],
      "metadata": {
        "id": "JQyVdlFCf2yd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['prExperience'], errors='ignore')\n",
        "\n",
        "# TODO: Figure out how to do this\n",
        "metrics['prExperience'] = 0\n"
      ],
      "metadata": {
        "id": "37dKywGDFPKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "9. **isMember:** Whether or not the author is a member or outside collaborator (True/False).\n"
      ],
      "metadata": {
        "id": "IhSC6qwXf95V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['isMember'], errors='ignore')\n",
        "\n",
        "# TODO: Figure out how to tell if a user is a member\n",
        "metrics['isMember'] = False\n"
      ],
      "metadata": {
        "id": "DW_ZiHEHFPEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "10. **commentsTotalCount:** The # of comments left on a PR\n"
      ],
      "metadata": {
        "id": "ac9ifXkVgLqx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (rentrant code)\n",
        "metrics.drop(columns=['commentsTotalCount'], errors='ignore', inplace=True)\n",
        "\n",
        "# Count the number of Comments for the Pull Request, name the column what we want.\n",
        "pr_comments_count = pr_comments.groupby(['pr_id']).size().reset_index(name='commentsTotalCount')\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, pr_comments_count, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframe\n",
        "pr_comments_count = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['commentsTotalCount'] = metrics['commentsTotalCount'].fillna(0).astype(int)\n"
      ],
      "metadata": {
        "id": "2BNmsnGIFO9Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "11. **authorComments:** The # of comments left by the PR author\n"
      ],
      "metadata": {
        "id": "LoBAgwxOgaJn"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "322b4128"
      },
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['authorComments'], errors='ignore')\n",
        "\n",
        "# Filter comments to only include those made by the PR author\n",
        "# Need to merge with metrics to get the author_id for each pr_comment\n",
        "author_comments = pd.merge(pr_comments, metrics[['pr_id', 'user_id']], left_on='pr_id', right_on='pr_id', how='left')\n",
        "author_comments = author_comments[author_comments['user_id_x'] == author_comments['user_id_y']]\n",
        "\n",
        "# Count the number of author comments per pull request\n",
        "author_comments_count = author_comments.groupby(['pr_id']).size().reset_index(name='authorComments')\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, author_comments_count, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframes\n",
        "author_comments = None\n",
        "author_comments_count = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['authorComments'] = metrics['authorComments'].fillna(0).astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "12. **reviewersComments:** The # of comments left by the reviewers who participate in the disucssion\n"
      ],
      "metadata": {
        "id": "0cC_Qh-DgvEJ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "454479f7"
      },
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['reviewersComments'], errors='ignore')\n",
        "\n",
        "# Filter comments to exclude those made by the PR author\n",
        "# Need to merge with metrics to get the author_id for each pr_comment\n",
        "reviewer_comments = pd.merge(pr_comments, metrics[['pr_id', 'user_id']], left_on='pr_id', right_on='pr_id', how='left')\n",
        "reviewer_comments = reviewer_comments[reviewer_comments['user_id_x'] != reviewer_comments['user_id_y']]\n",
        "\n",
        "# Count the number of reviewer comments per pull request\n",
        "reviewer_comments_count = reviewer_comments.groupby(['pr_id']).size().reset_index(name='reviewersComments')\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, reviewer_comments_count, left_on='pr_id', right_on='pr_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframes\n",
        "reviewer_comments = None\n",
        "reviewer_comments_count = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['reviewersComments'] = metrics['reviewersComments'].fillna(0).astype(int)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "13. **reviewersTotalCount:** The # of developers who participate in the discussion.\n"
      ],
      "metadata": {
        "id": "sDtcHmxxg9MP"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4b294946"
      },
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['reviewersTotalCount'], errors='ignore')\n",
        "\n",
        "# Extract user_id from the nested 'user' column in pr_review_comments\n",
        "pr_review_comments['user_id_from_user'] = pr_review_comments['user'].apply(lambda x: x.get('id') if isinstance(x, dict) else None)\n",
        "\n",
        "# Extract user_id from the nested 'user' column in pr_reviews\n",
        "pr_reviews['user_id_from_user'] = pr_reviews['user'].apply(lambda x: x.get('id') if isinstance(x, dict) else None)\n",
        "\n",
        "# Get author_id from metrics for merging\n",
        "metrics['author_id_from_author'] = metrics['user'].apply(lambda x: x.get('id') if isinstance(x, dict) else None)\n",
        "\n",
        "\n",
        "# Get unique reviewer IDs from review comments, excluding the author\n",
        "reviewer_comments_users = pd.merge(pr_review_comments, metrics[['pr_id', 'author_id_from_author']], left_on='pull_request_review_id', right_on='pr_id', how='left')\n",
        "reviewer_comments_users = reviewer_comments_users[reviewer_comments_users['user_id_from_user'] != reviewer_comments_users['author_id_from_author']]\n",
        "reviewer_comments_users = reviewer_comments_users.groupby(['pull_request_review_id'])['user_id_from_user'].nunique().reset_index(name='reviewer_commenters')\n",
        "\n",
        "\n",
        "# Get unique reviewer IDs from reviews, excluding the author\n",
        "review_users = pd.merge(pr_reviews, metrics[['pr_id', 'author_id_from_author']], left_on='pr_id', right_on='pr_id', how='left')\n",
        "review_users = review_users[review_users['user_id_from_user'] != review_users['author_id_from_author']]\n",
        "review_users = review_users.groupby(['pr_id'])['user_id_from_user'].nunique().reset_index(name='reviewers')\n",
        "\n",
        "# Merge the two dataframes to get unique users from both sources\n",
        "reviewers_total = pd.merge(reviewer_comments_users, review_users, left_on='pull_request_review_id', right_on='pr_id', how='outer').fillna(0)\n",
        "\n",
        "# Calculate the total number of unique reviewers\n",
        "reviewers_total['reviewersTotalCount'] = reviewers_total['reviewer_commenters'] + reviewers_total['reviewers']\n",
        "reviewers_total = reviewers_total.drop(columns=['reviewer_commenters', 'reviewers'])\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, reviewers_total, left_on='pr_id', right_on='pull_request_review_id', how='left')\n",
        "\n",
        "# Garbage Collect temporary dataframes\n",
        "reviewer_comments_users = None\n",
        "review_users = None\n",
        "reviewers_total = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['reviewersTotalCount'] = metrics['reviewersTotalCount'].fillna(0).astype(int)\n",
        "\n",
        "# Drop the temporary user_id and author_id columns\n",
        "pr_review_comments = pr_review_comments.drop(columns=['user_id_from_user'], errors='ignore')\n",
        "pr_reviews = pr_reviews.drop(columns=['user_id_from_user'], errors='ignore')\n",
        "metrics = metrics.drop(columns=['author_id_from_author', 'pull_request_review_id'], errors='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "14. **repoAge:** Time interval between the repository creation time and PR creation time in days.\n"
      ],
      "metadata": {
        "id": "Bvwr_F_0h3p-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['repoAge', 'repo_created_at', 'repo_created_at_x'], errors='ignore')\n",
        "\n",
        "# Copy the Repository dataframe and remove the unnecessary columns\n",
        "repos_temp = (repos.copy()\n",
        "                   .drop(columns=['license', 'full_name', 'language', 'forks', 'stars', 'url'], errors='ignore'))\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, repos_temp, left_on='repo_id', right_on='repo_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary dataframe\n",
        "repos_temp = None\n",
        "\n",
        "# Drop from Metrics any Repo without a repo created date\n",
        "metrics = metrics.dropna(subset=['repo_created_at'])\n",
        "\n",
        "# Calculate the Repo Age in Days (created_at - repo_created_at), handling potential None values\n",
        "metrics = metrics.assign(repoAge=lambda x: (x['created_at'] - x['repo_created_at']).dt.days)\n",
        "\n",
        "# Drop the unnecessary Repo Created At column\n",
        "metrics = metrics.drop(columns=['repo_created_at'], errors='ignore')\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['repoAge'] = metrics['repoAge'].fillna(0).astype(int)"
      ],
      "metadata": {
        "id": "ZBVOYKNaFOcN",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "15. **state**: State of the pull request (MERGED or CLOSED).\n",
        "16. **bodyLength**: Length of the PR body (in characters).\n",
        "17. **reviewTime**: Time taken to review the PR (in hours, floating point, no rounding).\n"
      ],
      "metadata": {
        "id": "qNQdfoY8iNBa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['state', 'bodyLength', 'reviewTime'], errors='ignore')\n",
        "\n",
        "# Set the State to MERGED or CLOSED\n",
        "metrics['state'] = metrics['merged_at'].apply(lambda x: 'MERGED' if x is not None else 'CLOSED')\n",
        "\n",
        "# Get the Length of the Body of the Pull Request\n",
        "metrics['bodyLength'] = metrics['body'].str.len()\n",
        "\n",
        "# Calculate the Review Time\n",
        "metrics['reviewTime'] = (metrics['closed_at'] - metrics['created_at']).dt.total_seconds() / 3600"
      ],
      "metadata": {
        "id": "5Ftmm7qZlHbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project variables"
      ],
      "metadata": {
        "id": "1unf8guqcK2d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18. **repoLanguage:** Programming language of the repository (e.g., Python, PHP, TypeScript, Vue).\n",
        "*[I'm assuming its the top language as there is only one]*\n",
        "19. **forkCount:** The # of forks that a repository has\n",
        "20. **stargazerCount:** The # of stargazers that a repository has.\n"
      ],
      "metadata": {
        "id": "A5lSM-5VimJ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['repoLanguage', 'forkCount', 'stargazerCount'], errors='ignore')\n",
        "\n",
        "repos_temp = (repos.copy()\n",
        "                   .drop(columns=['license', 'repo_url', 'html_url', 'full_name'], errors='ignore')\n",
        "                   .rename(columns={'language': 'repoLanguage', 'forks': 'forkCount', 'stars': 'stargazerCount'}))\n",
        "\n",
        "# Group by ID and get the First Record\n",
        "repos_temp = repos_temp.groupby(['repo_id']).first().reset_index() # Add reset_index() to make repo_id a column again\n",
        "\n",
        "# Merge the Dataframes using a left join\n",
        "metrics = pd.merge(metrics, repos_temp, left_on='repo_id', right_on='repo_id', how='left')\n",
        "\n",
        "# Garbage Collect the temporary Dataframe\n",
        "repos_temp = None\n",
        "\n",
        "# Fill N/A values with defaults\n",
        "metrics['repoLanguage'] = metrics['repoLanguage'].fillna('other')\n",
        "metrics['forkCount'] = metrics['forkCount'].fillna(0).astype(int)\n",
        "metrics['stargazerCount'] = metrics['stargazerCount'].fillna(0).astype(int)"
      ],
      "metadata": {
        "id": "hEoTBBXjFOVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Treatment variables"
      ],
      "metadata": {
        "id": "RV-ykVvwcSGJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21. **With Copilot for PRs:** Whether or not a PR is generated by Copilot for PRs (binary)\n"
      ],
      "metadata": {
        "id": "zUDj9SFMjShm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (rentrant code)\n",
        "metrics = metrics.drop(columns=['reviewTime'], errors='ignore')\n",
        "\n",
        "# Was the PR created by Copilot\n",
        "metrics['With Copilot for PRs'] = metrics['agent'].apply(lambda x: 1 if x == 'copilot' else 0)"
      ],
      "metadata": {
        "id": "btn7vVCnjSTb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Outcome variables"
      ],
      "metadata": {
        "id": "iRzFbe-Acwbw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22. **Review time (reviewTime):** Time interval between the PR creation time and closed time in hours\n"
      ],
      "metadata": {
        "id": "0Nzqcx6Yi6Uo"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61c5c683",
        "collapsed": true
      },
      "source": [
        "# Make sure we don't crash because the columns already exist (rentrant code)\n",
        "metrics = metrics.drop(columns=['reviewTime'], errors='ignore')\n",
        "\n",
        "# Calculate review time in hours, handling potential NaT values\n",
        "metrics = metrics.assign(reviewTime=lambda x: (x['closed_at'] - x['created_at']).dt.total_seconds() / 3600)\n",
        "\n",
        "# Fill N/A values with defaults (e.g., for open PRs)\n",
        "metrics['reviewTime'] = metrics['reviewTime'].fillna(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "23. **Is merged (state):** Whether or not a PR is merged (binary)\n"
      ],
      "metadata": {
        "id": "-QSkr74njEzs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure we don't crash because the columns already exist (reentrant code)\n",
        "metrics = metrics.drop(columns=['isMerged'], errors='ignore')\n",
        "\n",
        "# If Merged_At is None, the PR was not merged, otherwise it was\n",
        "metrics['isMerged'] = metrics['merged_at'].apply(lambda x: 0 if x is None else 1)"
      ],
      "metadata": {
        "id": "fvl0rnKHbOwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Order in CSV (treatment_metrics.csv and control_metrics.csc)\n",
        "\n",
        "1. **repoLanguage**\n",
        "2. **forkCount**\n",
        "3. **stargazerCount**\n",
        "4. **repoAge**\n",
        "5. **state**\n",
        "6. **deletions**\n",
        "7. **additions**\n",
        "8. **changedFiles**\n",
        "9. **commentsTotalCount**\n",
        "10. **commitsTotalCount**\n",
        "11. **prExperience**\n",
        "12. **isMember**\n",
        "13. **authorComments**\n",
        "14. **reviewersComments**\n",
        "15. **reviewersTotalCount**\n",
        "16. **bodyLength**\n",
        "17. **prSize**\n",
        "18. **reviewTime**\n",
        "19. **purpose**\n"
      ],
      "metadata": {
        "id": "0-kgS2O2dL6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "csv_order = ['repoLanguage',\n",
        "'forkCount',\n",
        "'stargazerCount',\n",
        "'repoAge',\n",
        "'state',\n",
        "'deletions',\n",
        "'additions',\n",
        "'changedFiles',\n",
        "'commentsTotalCount',\n",
        "'commitsTotalCount',\n",
        "'prExperience',\n",
        "'isMember',\n",
        "'authorComments',\n",
        "'reviewersComments',\n",
        "'reviewersTotalCount',\n",
        "'bodyLength',\n",
        "'prSize',\n",
        "'reviewTime',\n",
        "'purpose']\n",
        "\n",
        "# Remove unnecessary columns\n",
        "metrics = metrics.loc[:, csv_order]\n",
        "# Put the Columns in the right order\n",
        "metrics = metrics[csv_order]\n",
        "\n",
        "display(metrics.columns)\n",
        "display(len(pull_request))\n",
        "display(len(metrics))"
      ],
      "metadata": {
        "id": "KNB1iJ34WyMx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "3bd5cbb4-b81b-4995-eed0-4ffa568b9ca4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Index(['repoLanguage', 'forkCount', 'stargazerCount', 'repoAge', 'state',\n",
              "       'deletions', 'additions', 'changedFiles', 'commentsTotalCount',\n",
              "       'commitsTotalCount', 'prExperience', 'isMember', 'authorComments',\n",
              "       'reviewersComments', 'reviewersTotalCount', 'bodyLength', 'prSize',\n",
              "       'reviewTime', 'purpose'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "932791"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "20751"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fourth**, Bot detection and filtering employed the methodology of Golzadeh et al. (2022)\n",
        "\n",
        "simple “bot” username suffix check with a comprehensive, manually verified list of 527 bot accounts\n",
        "* groundtruthbots.csv - a list of bots from Golzadeh et al.\n"
      ],
      "metadata": {
        "id": "V8vXCVjGW1aV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bots_list = pd.read_csv(\"https://raw.githubusercontent.com/awjans/CopilotForPRsAdoption/main/data/groundtruthbots.csv\", engine='python')"
      ],
      "metadata": {
        "id": "AqXYcUmgxz1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Fifth**, Adoption Trend (RQ1)\n",
        "\n",
        "* Counted occurrences of each marker tag; copilot:summary was the most frequent (13 231 instances).\n",
        "* Visualised cumulative PRs over time (Fig. 3) and proportion of PRs per repository (Fig. 4).\n"
      ],
      "metadata": {
        "id": "g4l6_AqBzYVI"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CNLP973ZzYBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sixth**, Causal Inference (RQ2)\n",
        "\n",
        "### Propensity‑Score Estimation\n",
        "Logistic regression (treatment = Copilot usage) on the 17 covariates.\n",
        "Estimated each PR’s probability of receiving the treatment (ps).\n",
        "### Weight Construction\n",
        "Inverse‑probability weights: 1/ps for treated, 1/(1‑ps) for control.\n",
        "### Entropy Balancing\n",
        "Applied the entropy‑balancing algorithm (equivalent to R’s ebalance) to adjust the raw weights so that the weighted means of all covariates matched exactly between groups.\n",
        "After balancing, absolute mean differences for every covariate were ≤ 0.10 (Fig. 2).\n",
        "### Outcome Regression\n",
        "* Review time (continuous): weighted ordinary least squares (lm analogue) with only the treatment indicator. The coefficient gave the Average Treatment Effect on the Treated (ATT) of ‑19.3 h (p ≈ 1.6 × 10⁻¹⁷).\n",
        "* Merge outcome (binary): weighted logistic regression (glm with logit link). The exponentiated treatment coefficient yielded an odds ratio of 1.57 (95 % CI [1.35, 1.84], p < 0.001).\n",
        "These two models answer RQ2.1 (review‑time reduction) and RQ2.2 (higher merge likelihood).\n"
      ],
      "metadata": {
        "id": "48T4d5AezoVx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The R Scripts\n",
        "The main difference between PMW_merge.R and PMW_review.R is:\n",
        "\n",
        "* PMW_merge.R includes the column isMerged, which indicates whether each pull request was merged (state == \"MERGED\"). This column is added to the modeling data and used in the analysis.\n",
        "* PMW_review.R does not include the isMerged column in its modeling data; it focuses only on review-related metrics.\n",
        "* Otherwise, both scripts process the same input data, use similar covariates, and prepare for causal inference analysis. The inclusion of isMerged in PMW_merge.R allows for analysis related to PR merge status, while PMW_review.R is focused on review characteristics."
      ],
      "metadata": {
        "id": "kNvRCCdDFmIf"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5GN6LEJdGbVD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}